* Analysis I
** Real analysis - Jirí Leb
*** Basic set theory
    1. Set building notation
       + $S := \{x \in A : P(x)\}$
    2. Proper subset
       + A set A is a proper subset of B if $A \subset B$ and $A \neq B$. We write $A \subsetneq B$.
    3. Well ordering property of $\mathbb{N}$
       + Every nonempty subset of $\mathbb{N}$ has a least (smallest) element.
    4. Cartesian product
       + $A ừ B := \{(x;y) : x \in A,y \in B\}$
    5. Cardinality
       + Let A and B be sets. We say A and B have the same cardinality when there exists a bijection f : A \to B. We denote by |A| the equivalence class of all sets with the same cardinality as A and we simply call |A| the cardinality of A.
    6. Countably infinite
       + If |A| = |N|, then A is said to be /countably infinite/. If A is /finite/ or /countably infinite/, then we say A is /countable/. If A is not countable, then A is said to be /uncountable/.
    7. Power set
       + The power set of a set A, denoted by P(A), is the set of all subsets of A.
    8. Theorem (Cantor )
       + $|A| < |\mathbb{P}(A)|$. In particular, there exists no surjection from A onto $\mathbb{P}(A)$.
*** Chap 1: Real Numbers
    1. Ordered set
       + An ordered set is a set S together with a relation < such that
	 * (trichotomy) For all x,y \in S, exactly one of x < y, x = y, or y < x holds.
	 * (transitivity) If x,y,z \in S are such that x < y and y < z, then x < z.
    2. Least-upper-bound property
       + An ordered set S has the least-upper-bound property if every nonempty subset E \subset S that is bounded above has a least upper bound, that is sup E exists in S. The least-upper-bound property is sometimes called the /completeness property/ or the /Dedekind completeness property/.
    3. Theorem (*Archimedean property*)
       + (/Archimedean property/) If x,y $\in \mathbb{R}$ and x > 0, then there exists an n $\in \mathbb{N}$ such that nx > y.
       + ($\mathbb{Q}$ is dense in $\mathbb{R}$) If x,y $\in \mathbb{R}$ and x < y, then there exists an r $\in \mathbb{Q}$ such that x < r < y.
    4. Decimal representation of the reals
       + Every infinite sequence of digits 0.d1d2d3... represents a unique real number x \in [0,1], and $D_{n} \leq x \leq D_{n} + \dfrac{1}{10^{n}}$ for all n \in  N.
       + For every x \in (0,1] there exists an infinite sequence of digits 0.d1d2d3... that represents x. There exists a unique representation such that  $D_{n} < x \leq D_{n} + \dfrac{1}{10^{n}}$ for all n \in N.
    5. Theorem  (Cantor). The set (0,1] is uncountable. (proof using /Cantor diagonalization/ trick)
*** Chap 2: Sequences and series
    1. Sequence notation
       + $\{x_n\}$ or $\{x_n\}_{n=1}^\infty$
    2. Bounded sequences
       + A sequence $\{x_n\}$ is bounded if there exists a $B \in \mathbb{R}$ such that $|x_n| \leq B$ for all $n \in \mathbb{N}$.
    3. Tail of a sequence
       + For a sequence $\{x_n\}$, the K-tail (where K \in N), or just the tail, of $\{x_n\}$ is the sequence starting at K +1, usually written as $\{x_{n+K}\}_{n=1}^\infty$ or $\{x_{n}\}_{n=K+1}^\infty$.
    4. Subsequences
       + Let $\{x_n\}$ be a sequence. Let $\{n_i\}$  be a strictly increasing sequence of natural numbers, that is, n_i < n_{i+1} for all i (in other words n_1 < n_2 < n_3 < ởởở). The sequence $\{x_{n_i}\}_{i=1}^\infty$ is called a subsequence of $\{x_n\}$
    5. Limit superior, limit inferior, and *Bolzano-Weierstrass*
       + /Upper and lower limits/:
	 Let $\{x_n\}$ be a bounded sequence. Define the sequences $\{a_n\}$ and $\{b_n\}$ by $a_n := sup\{x_k: k\geq n\}$ and $b_n := inf\{x_k: k\geq n\}$. Define, if the limits exist, \[ \limsup_{n\to\infty} x_n := \lim_{n\to\infty} a_n, \] \[ \liminf_{n\to\infty} x_n := \lim_{n\to\infty} b_n, \]
       + Proposition:
	 Let $\{x_n\}$ be a bounded sequence. Then $\{x_n\}$ converges if and only if $\liminf_{n\to\infty} x_n = \limsup_{n\to\infty} x_n$ Furthermore, if $\{x_n\}$ converges, then $\lim_{n\to\infty} x_n = \liminf_{n\to\infty} x_n = \limsup_{n\to\infty} x_n$.
       + *Bolzano-Weierstrass theorem*:
	 Suppose a sequence $\{x_n\}$ of real numbers is bounded. Then there exists a convergent subsequence $\{x_{n_i}\}$.
    6. Cauchy sequences
       + A sequence $\{x_n\}$ is a /Cauchy sequence/ if for every $\epsilon > 0$ there exists an M \in N such that for all n \geq M and all k \geq M, we have $|x_n - x_k| < \epsilon$
       + A Cauchy sequence is bounded /(proposition)/
       + A sequence of real numbers is Cauchy if and only if it converges. /(Theorem)/.
       + The Cauchy criterion is stronger than $|x_{n+1} - x_n|$ (or $|x_{n+j} - x_n|$ for a fixed j) going to zero as n goes to infinity. When we get to the partial sums of the harmonic series, we will have a sequence such that $x_{n+1} - x_n = \frac{1}{n}$, yet $\{x_n\}$ is divergent. In fact, for that sequence, $\lim_{n\to\infty}|x_{n+j} - x_n| = 0$ for every $j \in \mathbb{N}$. */The key point in the definition of Cauchy is that n and k vary independently and can be arbitrarily far apart./*
       + The statement of this proposition is sometimes used to define the completeness property of the real numbers. We say a set is /Cauchy-complete/ (or sometimes just /complete/) if every Cauchy sequence converges. One can construct R via "completing" Q by "throwing in" just enough points to make all Cauchy sequences converge. The resulting field has the least-upper-bound property. The advantage of using Cauchy sequences to define completeness is that this idea generalizes to more abstract settings such as metric spaces.
    7. Series
       - /Definition/:
	 Given a sequence $\{x_n\}$, we write the formal object $\sum_{n=1}^\infty x_n$ or sometimes just $\sum x_n$ and call it a series. A series /converges/ if the sequence $\{s_k\}$ defined by $s_k := \sum_{n=1}^k x_n = x_1 + x_2 + ... + x_k$, converges. The numbers $s_k$ are called /partial sums/
       - Geometric series:
	 Suppose -1 < r < 1. Then the geometric series $\sum_{n=0}^\infty r^n$ converges, and \[\sum_{n=0}^{k-1} r^n = \dfrac{1-r^k}{1-r} \hspace{0.5cm} ,\] \[\sum_{n=0}^\infty r^n = \dfrac{1}{1-r} \hspace{0.5cm} .\]
       - /Cauchy series/:
	 A series $\sum x_n$  is said to be Cauchy or a Cauchy series if the sequence of partial sums $\{s_n\}$ is a Cauchy sequence.
       - /Harmonic series/:
	 The series $\sum \frac{1}{n}$ diverges (despite the fact that $\lim \frac{1}{n} = 0$).
       - */Basic properties of series/*
	 + Linearity of series (proposition).
	   Let $\alpha \in R$ and $\sum x_n$ and $\sum y_n$ be convergent series. Then \\
	   (i) $\sum x_n$ is a convergent series and $\sum_{n=1}^\infty\alpha x_n = \alpha\sum_{n=1}^\infty x_n$. \\
	   (ii) $\sum(x_n +y_n)$ is a convergent series and $\sum_{n=1}^\infty(x_n + y_n) = \sum_{n=1}^\infty x_n + \sum_{n=1}^\infty y_n$.\\
	   (*) /note/ _this does not hold if the series is not convergence._
       - /Absolute convergence/:
	 A series $\sum x_n$  converges absolutely if the series $\sum |x_n|$ converges. If a series converges, but does not converge absolutely, we say it is /conditionally convergent/.
       - /The p-series of p-test/:
	 For $p \in \mathbb{R}$, the series $\sum_{n=1}^\infty \frac{1}{n^p}$ converges if and only if $p > 1$.
       - /Ratio test/:
	 Let $\sum |x_n|$ be a series, $x_n \neq 0$ for all n, and such that
	 \[L := \lim_{n\to\infty} \frac{|x_n + 1|}{x_n} \quad \text{exists.}\]
	 \[\textrm{(i) If $L < 1$, then $\sum |x_n|$ converges absolutely.}\]
	 \[\mbox{(ii) If $L > 1$, then $\sum |x_n|$ diverges.}\]
       - /Root test/:
	 Let $\sum |x_n|$ be a series and let \[L := \limsup_{n\to\infty}|x_n|^{\frac{1}{n}}\]
	 \[\text{(i) If $L < 1$, then $\sum |x_n|$ converges absolutely.}\]
	 \[\text{(ii) If $L > 1$, then $\sum |x_n|$ diverges.}\]
       - /Alternating series test/:
	 Let $\{x_n\}$ be a monotone decreasing sequence of positive real numbers such that lim x_n = 0. Then $\sum_{n=1}^\infty (-1)^nx_n$ converges.
       - */Rearrangements/*:
	 - Absolutely convergent series can be summed in any order whatsoever. */Nothing of the sort holds for conditionally convergent series/*
       - /Multiplication of series/:
	 - Mertens' theorem:
	   Suppose $\sum_{n=0}^\infty a_n$ and $\sum_{n=0}^\infty b_n$ are two convergent series, converging to A and B respectively. If at least one of the series converges absolutely, then the series $\sum_{n=0}^\infty c_n$ where $c_n = a_0b_n + a_1b_{n-1} + ... + a_nb_0 = \sum_{j=0}^n a_jb_{n-j}$ converges to AB.
	   The series $\sum c_n$ is called the /Cauchy product/ of $\sum a_n$ and $\sum b_n$.
       - /Power series/:
	 - Fix x_0 \in R. A power series about x_0 is a series of the form $\sum_{n=0}^\infty a_n(x-x_0)^n$.
	 - Proposition (/radius of convergence of the power series/):
	   Let $\sum_{n=0}^\infty a_n(x-x_0)^n$ be a power series, and let $R := \limsup_{n\to\infty}|a_n|^\frac{1}{n}$. If $R = \infty$, the power series is divergent. If R = 0, then the power series converges everywhere. Otherwise, the radius of convergence $\rho = \frac{1}{R}$.
*** Chap 3: Countinuos functions
    1. /Cluster points/:
       Let $S \subset R$ be a set. A number $x \in R$ is called a cluster point of S if for every $\epsilon > 0$, the set $(x-\epsilon, x + \epsilon)\cap S \setminus \{x\}$ is not empty.
    2. /Restriction of fuction/:
       Let $f : S \to R$ be a function and $A \subset S$. Define the function \[f|_A : A \to R \text{ by } f|_A(x) := f(x) \text{ for } x \in A.\] The function $f|_A$ is called the restriction of f to A.
    3. /Uniform continuity/:
       Let $S \subset R$, and let $f : S \to R$ be a function. Suppose for every $\epsilon > 0$ there exists a $\delta > 0$ such that whenever $x,c \in S$ and $|x-c| < \delta$, then $|f(x)-f(c)| < \epsilon$. Then we say $f$ is /uniformly continuous./
    4. Theorem: Let $f : [a,b] \to R$ be a continuous function. Then $f$ is uniformly continuous.
    5. /Lipschitz continuous functions/:
       A function $f : S \to R$ is Lipschitz continuous, if there exists a $K \in R$, such that $|f(x)-f(y)| \leq K|x-y|$ for all x and y in S. \[ \textbf{note:} \textit{ uniformly continuous is not always Lipschitz continuous, ex: } \sqrt{|x|}.\]
*** Chap 4: The derivative
    1. /Mean value theorem/:
       Let $f : [a,b] \to R$ be a continuous function differentiable on (a,b). Then there exists a point c \in (a,b) such that f(b)-f(a) = f'(c)(b-a).
    2. /Cauchy's mean value theorem/:
        Let $f : [a,b] \to R$ and $\varphi : [a,b]\to R$ be continuous functions differentiable on $(a,b)$. Then there exists a point $c \in (a,b)$ such that \[(f(b)-f(a))\varphi'(c) = f'(c)(\varphi(b)-\varphi(a)).\]
    3. /Taylor's theorem/
       + Definition:
	 For an n times differentiable function f defined near a point $x_0 \in R$, define the $nth$ order Taylor polynomial for f at $x_0$ as
	 \[P_n^{x_0}(x):= \sum_{k=0}^n\dfrac{f^{(k)}(x_0)}{k!}(x-x_0)^k\]
	 \[= f(x_0) + f'(x_0)(x-x_0) + \dfrac{f''(x_0)}{2}(x-x_0)^2 + ... + \dfrac{f^{(n)}(x_0)}{n!}(x-x_0)^n.\]
       + /Theorem (Taylor)/:
	 /Taylor's theorem is a generalization of the mean value theorem/.
	 Suppose $f : [a,b] \to R$ is a function with n continuous derivatives on $[a,b]$ and such that $f^{(n+1)}$ exists on $(a,b)$. Given distinct points $x_0$ and $x$ in $[a,b]$, we can find a point $c$ between $x_0$ and $x$ such that
	 \[f(x) = P_n^{x_0}(x)+ \dfrac{f^{(n+1)}(c)}{(n+1)!}(x-x_0)^{n+1}.\]
	 The term $R_n^{x_0}(x):= \dfrac{f^{(n+1)}(c)}{(n+1)!}(x-x_0)^{n+1}$ is called $\textit{the remainder term}$. This form of the remainder term is called the $\textit{Lagrange form}$ of the remainder. There are other ways to write the remainder term.
       + /Taylor's series:/
	 If $f$ is infinitely differentiable, that is, if $f$ can be differentiated any number of times, then we define the Taylor series:
	 \[\sum_{k=0}^{\infty}\dfrac{f^{(k)}(x_0)}{k!}(x-x_0)^k\]
	 There is no guarantee that this series converges for any $x \neq x_0$. */And even where it does converge, there is no guarantee that it converges to the function f/*. Functions f whose Taylor series at every point $x_0$ converges to f in some open interval containing $x_0$ are called /analytic functions/. Most functions one tends to see in practice are analytic.	 
*** Chap 5: The Riemann Intergral
    1. /Improper integrals/:
       Suppose $f:[a,b) \to R$ is a function (not necessarily bounded) that is Riemann integrable on $[a,c]$ for all $c < b$. We define
       \[\int_a^b f:=\lim_{c \to b^-}\int_a^c f \text{ if the limit exists.}\]
       Suppose $f:[a,\infty)\to R$ is a function such that $f$ is Rieman integrable on $[a,c]$ for all $c < \infty$. We define
       \[\int_a^{\infty} f:= \lim_{c \to \infty}\int_a^c f \text{ if the limit exists.}\]
       If the limit exists, we say the improper integral converges. If the limit does not exist, we say the improper integral diverges.
    2. /Integral test for series/
       Suppose $f : [k,\infty) \to R$ is a decreasing nonnegative function where $k \in \mathbb{Z}$. Then
       \[\sum_{n=k}^\infty f(n) \text{ converges if and only if } \int_k^\infty f \text{ converges.}\]
       \[\text{In this case } \int_k^\infty f \leq \sum_{n=k}^\infty f(n) \leq f(k) + \int_k^\infty f.\]
*** Chap 6: Sequences of Functions
    1. /Pointwise and uniform convergence/:
       - /Pointwise convergence:/
	 For every $n \in \mathbb{N}$, let $f_n : S \to R$ be a function. The sequence ${f_n}_{n=1}^\infty converges pointwise to $f: S \to R$ if for every $x \in S$, we have
	 \[f(x) = \lim_{n \to \infty}f_n(x).\]
	 Limits of sequences of numbers are unique, and so if a sequence ${f_n} converges pointwise, the limit function $f$ is unique. It is common to say that $f_n : S \to R$ converges to $f$ on $T \subset S$ for some $f: T \to R$. In that case we mean $f(x) = \lim f_n(x)$ for every $x \in T$. In other words, the restrictions of $f_n$ to $T$ converge pointwise to $f$ .
       - /Uniform convergence:/
	 Let $f_n: S \to R$ and $f: S \to R$ be functions. The sequence ${f_n}$ converges uniformly to $f$ if for every $\epsilon > 0$, there exists an $N \in \mathbb{N}$ such that for all $n \geq N$, we have
	 \[|f_n(x)- f(x)| < \epsilon \text{ for all } x \in S.\]
	 In uniform convergence, N cannot depend on x (different from pointwise convergence). Given $\epsilon > 0$, we must find an N that works for all $x \in S$.h
       - /Convergence in uniform norm:/
	 Let $f: S \to R$ be a bounded function. Define
	 \[\|f\|_u := sup\{|f(x)| : x \in S\}.\]
	 We call $\|.\|_u$ the uniform norm.
	 To use this notation and this concept, the domain S must be fixed. Some authors use the notation $\|f\|_S$ to emphasize the dependence on $S$.
       - Proposistion:
	 A sequence of bounded functions $f_n: S \to R$ converges uniformly to $f: S \to R$, if and only if
	 \[\lim_{n\to\infty} \|f_n - f|\|_u = 0.\]
       - /uniformly Cauchy:/
	 Let $f_n: S \to R$ be bounded functions. The sequence is /Cauchy in the uniform norm/ or /uniformly Cauchy/ if for every $\epsilon > 0$, there exists an $N \in \mathbb{N}$ such that for all $m,k \geq N$, $\|f_m - f_k\|_u < \epsilon$ (for all x \in S)
       - Proposistion:
	 Let $f_n: S \to R$ be bounded functions. Then ${f_n}$ is Cauchy in the uniform norm if and only if there exists an $f: S \to R$ and ${f_n}$ converges uniformly to $f$.
    2. /Interchange of limits:/
       - /Continuity of the limit:/
	 \[\textit{we asking this question: } \lim_{k\to\infty}f(x_k) = \lim_{k\to\infty}(\lim_{n\to\infty}f_n(x_k)) =? \lim_{n\to\infty}(\lim_{k\to\infty}f_n(x_k)) = \lim_{n\to\infty}f_n(x) = f(x)\]
	 (Theorem) Suppose $S \subset R$. Let ${f_n}$ be a sequence of continuous functions $f_n: S \to R$ converging uniformly to $f: S \to R$. Then $f$ is continuous.
       - /Intergral of the limit:/
	 Theorem: Let ${f_n}$ be a sequence of Riemann integrable functions $f_n: [a,b] \to R$ converging uniformly to $f: [a,b] \to R$. Then $f$ is Riemann integrable, and $\int_a^b f = \lim_{n\to\infty}\int_a^b f_n$.
       - /Derivative of the limit:/\\
	 While uniform convergence is enough to swap limits with integrals, it is not, however, enough to swap limits with derivatives, unless you also have uniform convergence of the derivatives themselves.\\
	 Let $I$ be a /bounded interval/ and let $f_n: I \to R$ be continuously differentiable functions. Suppose ${f'_n}$ converges uniformly to $g: I \to R$, and suppose $\{f_n(c)\}_{n=1}^\infty$ is a convergent sequence for some $c \in I$. Then ${f_n}$ converges uniformly to a continuously differentiable function $f: I \to R$, and $f' = g$.\\
	 The proof goes through without boundedness of $I$, except for the uniform convergence of $f_n$ to $f$. As an example suppose $I = R$ and let $f_n(x):= \dfrac{x}{n}$. Then $f'_n(x) = \dfrac{1}{n}$, which converges uniformly to $0$. However, ${f_n}$ converges to $0$ only pointwise.
       - /Convergence of power series:/
	 + Proposition:
	   Let $\sum_{n=0}^\infty c_n(x-a)^n$ be a convergent power series with a radius of convergence $\rho$, where $0 < \rho \leq \infty$. Then the series converges uniformly in $[a-r,a+r]$ whenever $0 < r < \rho$. In particular, the series defines a continuous function on $(a-r,a+r)$ (if $\rho < \infty$), or $\mathbb{R}$ (if $\rho = \infty$).
	 + Corollary:
	   Let $\sum_{n=0}^\infty c_n(x-a)^n$ be a convergent power series with a radius of convergence $0 < \rho \leq \infty$. Let $I:= (a-\rho,a+\rho)$ if $\rho < \infty$ or $I:= \mathbb{R}$ if $\rho = \infty$. Let $f: I \to \mathbb{R}$ be the limit. Then
	   \[\int_a^x f = \sum_{n=1}^\infty \frac{c_{n-1}}{n}(x-a)^n,\]
	   where the radius of convergence of this series is at least $\rho$.
** Analysis I - Tenrence Tao
*** Chap 2: Starting at the Beginning - The Natural Numbers
    1. */The Peano Axioms/*\\
       *Axiom 1*: $0$ is a natural number.\\
       *Axiom 2*: if $n$ is a natural number, then $n++$ is also a natural number.\\
       *Axiom 3*: $0$ is not the successor of any natural number.\\
       *Axiom 4*: Different natural numbers must have different successors; i.e., if $n, m$ are natural numbers and $n \neq m$, then $n++ \neq m++$. Equivalently, if $n++ = m++$ then we must have $n = m$.\\
       *Axiom 5*: /(Principle of mathematical induction)/. Let $P(n)$ be any property pertaining to a natural number $n$. Suppose that $P(0)$ is true, and suppose that whenever $P(n)$ is true,$P(n++)$ is also true. Then $P(n)$ is true for every natural number $n$.\\
       /*note:/ A remarkable accomplishment of modern analysis is that just by starting from these five very primitive axioms, and some additional axioms from set theory, we can build all the other number systems, create functions, and do all the algebra and calculus that we are used to.
*** Chap 3: Set theory
    1. Fundamentals
       - Definition:
	 (Informal) We define a set A to be any unordered collection of objects, e.g., {3, 8, 5, 2} is a set. If x is an object, we say that x is an element of A or $x \in A$ if x lies in the collection; otherwise we say that $x \notin A$. For instance, $3 \in \{1, 2, 3, 4, 5\}$ but $7 \notin \{ 1, 2, 3, 4, 5\}$.\\
	 *Axiom 1*: (Sets are objects). If A is a set, then A is also an object. In particular, given two sets A and B, it is meaningful to ask whether A is also an element of B.\\
	 *Axiom 2*: (Equality of sets). Two sets A and B are equal, A = B, iff every element of A is an element of B and vice versa. To put it another way, A = B if and only if every element x of A belongs also to B, and every element y of B belongs also to A.\\
	 *Axiom 3*: (Empty set). There exists a set $\emptyset$, known as the empty set, which contains no elements, i.e., for every object $x$ we have $x \notin \emptyset$. The empty set is also denoted {}.\\
	 *Axiom 4*: (Singleton sets and pair sets). If a is an object, then there exists a set {a} whose only element is a, i.e., for every object y, we have y \in {a} if and only if y = a; we refer to {a} as the singleton set whose element is a. Furthermore, if a and b are objects, then there exists a set {a, b} whose only elements are a and b; i.e., for every object y, we have y \in {a, b} if and only if y = a or y = b; we refer to this set as the pair set formed by a and b.\\
	 *Axiom 5*: (Pairwise union). Given any two sets A, B, there exists a set A ∪ B, called the union of A and B, which consists of all the elements which belong to A or B or both.\\
	 *Axiom 6*: (Axiom of specification). Let A be a set, and for each x \in A, let P(x) be a property pertaining to x (i.e., for each x \in A, P(x) is either a true statement or a false statement). Then there exists a set, called {x \in A : P(x) is true} (or simply {x \in A : P(x)} for short), whose elements are precisely the elements x in A for which P(x) is true. In other words, for any object y, y \in {x in A : P(x) is true} <=> (y \in A and P(y) is true). This axiom is also known as the /axiom of separation./ We sometimes write {x \in A | P(x)} instead of {x \in A : P(x)}\\
	 *Axiom 7*: (Replacement). Let A be a set. For any object x \in A, and any object y, suppose we have a statement P(x, y) pertaining to x and y, such that for each x \in A there is at most one y for which P(x, y) is true. Then there exists a set {y : P(x, y) is true for some x \in A}, such that for any object z, z \in {y : P(x, y) is true for some x \in A} <=> P(x, z) is true for some x \in A.\\
	 *Axiom 8*: (Infinity). There exists a set N, whose elements are called natural numbers, as well as an object 0 in N, and an object n++ assigned to every natural number n \in N, such that the Peano axioms hold.
    2. Russell's Paradox
       - *Axiom 9*:(Universal specification). (/Dangerous!/) Suppose for every object x we have a property P(x) pertaining to x (so that for every x, P(x) is either a true statement or a false statement). Then there exists a set {x : P(x) is true} such that for every object y,\\
	 y \in {x : P(x) is true} \leftrightarrow P(y) is true.\\
	 This axiom is also known as the /axiom of comprehension/. It asserts that every property corresponds to a set; if we assumed that axiom, we could talk about the set of all blue objects, the set of all natural numbers, the set of all sets, and so forth. This axiom also implies most of the axioms in the previous section. Unfortunately, */this axiom cannot be introduced into set theory, because it creates a logical contradiction known as Russell’s paradox./*
       - *Axiom 10* (Regularity). If A is a non-empty set, then there is at least one element x of A which is either not a set, or is disjoint from A.\\
	 The point of this axiom (which is also known as the axiom of foundation) is that it is asserting that at least one of the elements of A is so low on the hierarchy of objects that it does not contain any of the other elements of A. One particular consequence of this axiom is that sets are no longer allowed to contain themselves.
    3. Functions
       - *Axiom 11*: (Power set axiom). Let X and Y be sets. Then there exists a set, denoted Y^X, which consists of all the functions from X to Y , thus f \in Y \leftrightarrow Y^X ( f is a function with domain X and codomain Y ).\\
	 /The reason we use the notation Y^X to denote this set is that if Y has n elements and X has m elements, then one can show that Y X has n^m elements./\\
	 The set {Y : Y is a subset of X} is known as the power set of X and is denoted 2^X. For instance, if a, b, c are distinct objects, we have 2^{{a,b,c}} = {∅, {a}, {b}, {c}, {a, b}, {a, c}, {b, c}, {a, b, c}}.
       - *Axiom 12*: (Union). Let A be a set, all of whose elements are themselves sets. Then there exists a set $\bigcup$ A whose elements are precisely those objects which are elements of the elements of A, thus for all objects x, x \in $\bigcup$ A \leftrightarrow (x \in S for some S \in A).
       - *Remark*: The axioms of set theory that we have introduced (Axioms 1 - 12, excluding the dangerous Axiom 9) are known as the /Zermelo–Fraenkel axioms of set theory/. There is one further axiom we will eventually need, the famous /axiom of choice/, giving rise to the /Zermelo–Fraenkel–Choice (ZFC) axioms of set theory/.
    4. Cardinality
       - Definition 1: (Equal cardinality) We say that two sets X and Y have equal cardinality iff there exists a bijection f : X → Y from X to Y.
       - Definition 2: Let n be a natural number. A set X is said to have cardinality n, iff it has equal cardinality with {i \in N : 1 \leq i \leq n}. We also say that X has n elements iff it has cardinality n.
       - Definition (Finite sets). A set is finite iff it has cardinality n for some natural number n; otherwise, the set is called infinite. If X is a finite set, we use */#(X)/* to denote the cardinality of X.
*** Chap 5: The Real number
    1. Constructing real number using Cauhy sequences
       - Definition (Real numbers). A real number is defined to be an object of the form LIM_{n\to\infty} a_n, where (a_n)_{n=1}^{\infty} is a Cauchy sequence of rational numbers. Two real numbers LIM_{n\to\infty} a_n an and LIM_{n\to\infty} b_n are said to be equal iff (a_n)_{n=1}^{\infty} and (b_n)_{n=1}^{\infty} are equivalent Cauchy sequences. The set of all real numbers is denoted R.\\
	 /Note 1: the above formal "LIM" is not "lim", for more information see Analysis I - Tenrence Tao./\\
	 /Note 2: we can say the set of all real numbers exists using ZFC axioms./
       - Theorem (Existence of least upper bound). Let E be a non-empty subset of R. If E has an upper bound, (i.e., E has some upper bound M), then it must have exactly one least upper bound.
*** Chap 8: Infinite Sets
    1. Some interesting theorems:
       + Theorem 1:  Let $\sum_{n=0}^\infty$ an be a series which is conditionally convergent (i.e., convergent, but not absolutely convergent), and let $L$ be any real number. Then there exists a bijection $f: N \to N$ such that $\sum_{m=0}^\infty f(m)$ converges conditionally to $L$.
*** Chap 9: Continuous functions on R
    1. Definition /(Adherent points)/:
       Let X be a subset of R, and let x \in R. We say that x is an adherent point of X iff it is \epsilon-adherent to X for every \epsilon > 0.
    2. Definition /(Closure)/:
       Let X be a subset of R. The closure of X, sometimes denoted $\overline{X}$ is defined to be the set of all the adherent points of X.
    3. Defintion /(Limit point)/:
       Let X be a subset of the real line. We say that x is a limit point (or a /cluster point/) of X iff it is an adherent point of $X \backslash \{x\}$. We say that x is an isolated point of X if $x \in X$ and there exists some $\epsilon > 0$ such that $|x − y| > \epsilon$ for all $y \in  X \backslash \{x\}$.
    4. /Heine–Borel theorem for the line/
       Let X be a subset of R. Then the following two statements are equivalent:\\
       (a) X is closed and bounded.\\
       (b) Given any sequence $(a_n)_{n=0}^\infty$ of real numbers which takes values in X (i.e., a_n \in X for all n), there exists a subsequence $(a_{n_j})_{j=0}^\infty$ of the original sequence, which converges to some number L in X.
    5. /Equivalent sequences/:
       Let $(a_n)_{n=1}^\infty$ and $(b_n)_{n=1}^\infty$ be sequences of real numbers (/not necessarily bounded or convergent/). Then $(a_n)_{n=1}^\infty$ and $(b_n)_{n=1}^\infty$ are equivalent if and only if $\lim_{n\to\infty}(a_n- b_n)=0$.
    6. /(L`Hôpital`s rule)/
       Let a < b be real numbers, and let $f:[a, b] \to R$ and $g:[a, b] \to R$ be functions which are continuous on $[a, b]$ and differentiable on $(a, b]$. Suppose that $f(a)=g(a)=0$, that $g'$ is non-zero on $(a, b]$ (i.e., $g'(x)\neq 0$ for all $x \in (a, b])$, and $\lim_{x\to a;x\in (a,b]} \frac{f'(x)}{g'(x)}$ exists and equals L. Then $g(x)\neq 0$ for all $x \in (a, b]$, and $\lim_{x\to a;x\in (a,b]} \frac{f(x)}{g(x)}$  exists and equals L.
*** Chap 11: The Riemann Integral
    1. Definition /(connected)/:
       Let X be a subset of R. We say that X is connected iff X is nonempty and the following property is true: whenever x, y are elements in X such that x < y, the bounded interval [x, y] is a subset of X (i.e., every number between x and y is also in X).
    2. The Riemann–Stieltjes Integral:
       - Let I be a bounded interval, let $\alpha:I \to R$ be a monotone increasing function, and let $f:I \to R$ be a function. Then there is a /generalization of the Riemann integral, known as the Riemann–Stieltjes integral/. This integral is defined just like the Riemann integral, but with one twist: instead of taking the length |J| of intervals J, we take the $\alpha$ -length $\alpha[J]$.
       - Informally, $fd\alpha$ is essentially equivalent to $f\frac{d\alpha}{dx}dx$, when $\alpha$ is differentiable. However, /the advantage of the Riemann– Stieltjes integral is that it still makes sense even when $\alpha$ is not differentiable./
* Analyis II
** Analysis II - Tenrence Tao
*** Chap 1 - Metric space
    1. Definition /(Metric spaces)/
       A metric space (X, d) is a space X of objects (called points), together with a /distance function/ or /metric/ $d:X \times X \to [0, +\infty)$, which associates to each pair x, y of points in X a non-negative real number d(x, y) \geq 0. Furthermore, the metric must satisfy the following four axioms:\\
       (a) For any x \in X, we have d(x, x) = 0.\\
       (b) (Positivity) For any distinct x, y \in X, we have d(x, y) > 0.\\
       (c) (Symmetry) For any x, y \in X, we have d(x, y) = d(y, x).\\
       (d) (Triangle inequality) For any x, y, z \in X, we have d(x, z) \leq d(x, y) + d(y, z).\\
       In many cases it will be clear what the metric d is, and we shall abbreviate (X, d) as just X.
       - /(Euclidean spaces)/
	 Let n \geq 1 be a natural number, and let R^n be the space of n-tuples of real numbers:\\
	 R^n = {(x_1, x_2,..., x_n): x_1,..., x_n \in R}.\\
	 We define the /Euclidean metric/ (also called the l^2 metric) $d_{l^2}: R^n \times R^n \to R$ by
	 \[d_{l^2}((x_1,... ,x_n), (y_1,...,y_n)):= (\sum_{n=1}^n (x_i-y_i)^2)^{1/2}.\]
       - /(Taxicab metric)/
	 Again let n \geq 1, and let R_n be as before. But now we use a different metric d_{l^1}, the so-called taxicab metric (or l^1 metric), defined by
	 \[d_{l^1}((x_1,x_2,...,x_n), (y_1,y_2,...,y_n)) := \sum_{i=1}^n |x_i-y_i|.\]
       - /(Sup norm metric)/
	 Again let n \geq 1, and let R_n be as before. But now we use a different metric d_{l^\infty}, the so-called sup norm metric (or l^\infty metric), defined by
	 \[d_{l^\infty}((x_1,x_2,...,x_n), (y_1,y_2,...,y_n)) := sup\{|x_i - y_i| : 1 \leq i \leq n\}.\]
       - $l^p$ metrics, where $p \in [1, +\infty]$
       - /Discrete metric/
       - /Geodesics/
    2. Definition /(Convergence of sequences in metric spaces)/:
       Let m be an integer, (X, d) be a metric space, and let $(x^{(n)})_{n=m}^\infty$ be a sequence of points in X. Let x be a point in X. We say that $(x^{(n)})_{n=m}^\infty$ /converges to x with respect to the metric d/, if and only if the limit $\lim_{n\to\infty} d(x^{(n)}, x)$ exists and is equal to 0.
       - Proposition /(Equivalence of $l^1, l^2, l^\infty$)/
	 Let R^n be a Euclidean space, and let $(x^{(k)})_{k=m}^\infty$ be a sequence of points in R^n. $x_j^{(k)} \in R$ is the jth co-ordinate of $x^{(k)} \in R^n$. Let $x = (x_1,...,x_n)$ be a point in R^n. Then the following four statements are equivalent:\\
	 (a) $(x^{(k)})_{k=m}^\infty$ converges to x with respect to the Euclidean metric d_{l^2}.\\
	 (b) $(x^{(k)})_{k=m}^\infty$ converges to x with respect to the taxicab metric d_{l^1}.\\
	 (c) $(x^{(k)})_{k=m}^\infty$ converges to x with respect to the sup norm metric d_{l^\infty}.\\
	 (d) For every 1 \leq j \leq n, the sequence $(x^{(k)})_{k=m}^\infty$ converges to x_j. /(Notice that this is a sequence of real numbers, not of points in R^n./)
       - Note: Because of the equivalence of (a), (b), and (c), we say that the Euclidean, taxicab, and supnorm metrics on R^n are equivalent. (There are infinite-dimensional analogues of the Euclidean, taxicab, and sup norm metrics which are not equivalent)
       - Proposition /(Uniqueness of limits)/
	 Let (X, d) be a metric space, and let $(x^{(n)})_{n=m}^\infty$ be a sequence in X. Suppose that there are two points x, x' \in X such that $(x^{(n)})_{n=m}^\infty$ converges to x with respect to d, and $(x^{(n)})_{n=m}^\infty$ also converges to x' with respect to d. Then we have x = x'.
    3. Some Point-Set Topology of Metric Spaces
       - Definition /(Balls)/
	 Let $(X, d)$ be a metric space, let $x_0$ be a point in $X$, and let $r > 0$. We define the ball $B_{(X,d)}(x_0, r)$ in $X$, centered at $x_0$, and with radius $r$, in the metric $d$, to be the set $B_{(X,d)}(x_0, r):= \{x \in X: d(x, x_0) < r\}$.\\
	 When it is clear what the metric space $(X, d)$ is, we shall abbreviate $B_{(X,d)}(x_0, r)$ as just $B(x_0, r)$.
       - Definition /(Interior, exterior, boundary)/
	 Let $(X, d)$ be a metric space, let $E$ be a subset of $X$, and let $x_0$ be a point in $X$. We say that $x_0$ is an interior point of $E$ if there exists a radius $r > 0$ such that $B(x_0, r) \subseteq E$. We say that $x_0$ is an exterior point of $E$ if there exists a radius $r > 0$ such that $B(x_0, r) \cap E = \varnothing$. We say that $x_0$ is a boundary point of $E$ if it is neither an interior point nor an exterior point of $E$. The set of all interior points of $E$ is called the interior of $E$ and is sometimes denoted $int(E)$. The set of exterior points of $E$ is called the exterior of $E$ and is sometimes denoted $ext(E)$. The set of boundary points of E is called the boundary of E and is sometimes denoted $\partial E$.
       - Definition /(Closure)/
	 Let $(X, d)$ be a metric space, let $E$ be a subset of $X$, and let $x_0$ be a point in $X$. We say that $x_0$ is an adherent point of $E$ if for every radius $r > 0$, the ball $B(x_0, r)$ has a non-empty intersection with $E$. /The set of all adherent points of $E$ is called the closure of $E$/ and is denoted $\overline{E}$.\\
	 /*note:/ every points of E are adherent points, including isolated points.
       - Definition /(Open and closed sets)/
	 Let $(X, d)$ be a metric space, and let $E$ be a subset of $X$. We say that $E$ is closed if it contains all of its boundary points. We say that $E$ is open if it contains none of its boundary points. /If E contains some of its boundary points but not others, then it is neither open nor closed./\\
	 /*note:/ It is possible for a set to be simultaneously open and closed, if it has no boundary.\\
	 /*note 2:/ it is not just the choice of metric which determines what is open and what is not, it is also the choice of /ambient space/ X.\\
       - Definition /(Relative topology)/
	 Let $(X, d)$ be a metric space, let $Y$ be a subset of $X$, and let $E$ be a subset of $Y$ . We say that $E$ is relatively open with respect to $Y$ if it is open in the metric subspace $(Y, d|_{Y\times Y})$. Similarly, we say that $E$ is relatively closed with respect to $Y$ if it is closed in the metric space $(Y, d|_{Y\times Y})$.
    4. Cauchy Sequences and Complete Metric Spaces
       - Definition /(Limit points)/
	 Suppose that $(x^{(n)})_{n=m}^\infty$ is a sequence of points in a metric space $(X, d)$, and let $L \in X$. We say that $L$ is a limit point of $(x^{(n)})_{n=m}^\infty$ iff for every $N \geq m$ and $\epsilon > 0$ there exists */an/* $n \geq N$ such that $d(x^{(n)}, L) \leq \epsilon$.
       - Proposition:
	 Let $(x^{(n)})_{n=m}^\infty$ be a sequence of points in a metric space $(X, d)$, and let $L \in X$. Then the following are equivalent:\\
	 (i) $L$ is a limit point of $(x^{(n)})_{n=m}^\infty$.\\
	 (ii) There exists a subsequence $(x^{(n_j)})_{j=1}^\infty$ of the original sequence $(x^{(n)})_{n=m}^\infty$ which converges to $L$.\\
	 /*Note:/ Limit points is not always converge points.\\
	 /*Note2:/ "limit point of a set" is synonymous with "cluster/accumulation point of a set", this is not true for sequences (nor nets or filters). That is, the term "limit point of a sequence" is not synonymous with "cluster/accumulation point of a sequence". The limit points of a set should not be confused with adherent points (also called points of closure). A limit point can be characterized as an adherent point that is not an isolated point.
       - Definition /(Cauchy sequences)/
	 Let $(x^{(n)})_{n=m}^\infty$ be a sequence of points in a metric space $(X, d)$. We say that this sequence is a Cauchy sequence iff for every $\epsilon > 0$, there exists an $N \geq m$ such that $d(x^{(j)}, x^{(k)}) < \epsilon$ for all $j, k \geq N$.
       - Definition /(Complete metric spaces)/
	 A metric space $(X, d)$ is said to be complete iff every Cauchy sequence in $(X, d)$ is in fact convergent in $(X, d)$.
       - Proposition:\\
	 (a) Let $(X, d)$ be a metric space, and let $(Y, d|_{Y \times Y})$ be a subspace of $(X, d)$. If $(Y, d|_{Y \times Y})$ is complete, then $Y$ must be closed in $X$.\\
	 (b) Conversely, suppose that $(X, d)$ is a complete metric space, and $Y$ is a closed subset of $X$. Then the subspace $(Y, d|_{Y \times Y})$ is also complete.\\
	 /*Note:/ In contrast, an incomplete metric space such as $(Q, d)$ may be considered closed in some spaces (for instance, $Q$ is closed in $Q$) but not in others (for instance, $Q$ is not closed in $R$). Indeed, it turns out that given any incomplete metric space $(X, d)$, there exists a /completion/ $(\overline{X},\overline{d})$, which is a larger metric space containing $(X, d)$ which is complete, and such that $X$ is not closed in $\overline{X}$ (indeed, the closure of $X$ in $(\overline{X}, \overline{d})$ will be all of $X$).
    5. Compact Metric spaces
       - Definition /(Compactness)/
	 A metric space $(X, d)$ is said to be compact iff every sequence in $(X, d)$ has at least one convergent subsequence. A subset $Y$ of a metric space $X$ is said to be compact if the subspace $(Y, d|_{Y \times Y})$ is compact.
       - Remark:
	 The notion of a set $Y$ being compact is /intrinsic/, in the sense that it only depends on the metric function $d|_{Y \times Y} restricted to $Y$, and not on the choice of the ambient space $X$. The notions of completeness, and of boundedness, are also intrinsic, but the notions of open and closed are not.
       - Definition /(Bounded sets)/
	 Let $(X, d)$ be a metric space, and let $Y$ be a subset of $X$. We say that $Y$ is bounded iff for every $x \in X$ there exists a ball $B(x, r)$ in $X$ of some finite radius $r$ which contains $Y$ . We call the metric space $(X, d)$ bounded if $X$ is bounded.
       - Proposition:
	 Let $(X, d)$ be a compact metric space. Then $(X, d)$ is both complete and bounded.
       - Theorem /(Heine–Borel theorem)/
	 Let $(R_n, d)$ be a Euclidean space with either the Euclidean metric, the taxicab metric, or the sup norm metric. Let E be a subset of $R_n$. Then $E$ is compact if and only if it is closed and bounded.\\
	 /*Note:/ However, the Heine–Borel theorem is not true for more general metrics. For instance, the integer Z with the discrete metric is closed (indeed, it is complete) and bounded, but not compact, since the sequence 1, 2, 3, 4, . . . is in Z but has no convergent subsequence.
*** Chap 2 - Continous functions on metric spaces
    1. Continous functions
       - Definition /(Continuous functions)/
	  Let $(X, d_X)$ be a metric space, and let $(Y, d_Y)$ be another metric space, and let $f: X \to Y$ be a function. If $x_0 \in X$, we say that $f$ is continuous at $x_0$ iff for every $\epsilon > 0$, there exists a $\delta > 0$ such that $d_Y(f(x),f (x_0)) < \epsilon$ whenever $d_X(x, x_0) < \delta$. We say that $f$ is continuous iff it is continuous at every point $x \in X$.
    2. Continuity and Connectedness
       - Definition /(Connected spaces)/
	 Let $(X, d)$ be a metric space. We say that $X$ is disconnected iff there exist disjoint non-empty open sets $V$ and $W$ in $X$ such that $V \cup W = X$. (Equivalently, $X$ is disconnected if and only if $X$ contains a non-empty proper subset which is simultaneously closed and open.) We say that $X$ is connected iff it is non-empty and not disconnected. We declare the empty set $\emptyset$ as being special—it is neither connected nor disconnected; one could think of the empty set as “unconnected”.
    3. Topological spaces:
       - Definition /(Topological spaces)/
	 A topological space is a pair $(X, F)$, where $X$ is a set and $F \subseteq 2^X$ is a collection of subsets of $X$, whose elements are referred to as /open sets/. Furthermore, the collection $F$ must obey the following properties:\\
	 • The empty set $\varnothing$ and the whole set $X$ are open; in other words, $\varnothing \in F$ and $X \in F$.\\
	 • Any finite intersection of open sets is open.\\
	 • Any arbitrary union of open sets is open (including infinite unions).\\
	 In many cases, the collection $F$ of open sets can be deduced from context, and we shall refer to the topological space $(X, F)$ simply as $X$.
       - Definition /(Neighborhoods)/
	 Let $(X, F)$ be a topological space, and let $x \in X$. A neighborhood of $x$ is defined to be any open set in $F$ which contains $x$.
       - Definition /(Topological convergence)/
	 Let m be an integer, (X, F) be a topological space and let $(x^{(n)})_{n=m}^\infty$ be a sequence of points in X. Let x be a point in X. We say that $(x^{(n)})_{n=m}^\infty$ converges to x if and only if, for every neighborhood V of x, there exists an N \geq m such that $x^{(n)} \in V$ for all n \geq N.\\
	 /*Note:/ This notion is consistent with that of convergence in metric spaces. One can then ask whether one has the basic property of uniqueness of limits. The answer turns out to usually be yes—if the topological space has an additional property known as the /Hausdorff property/—but the answer can be no for other topologies.
       - Definition /(Hausdorff property)/
	 A topological space (X, F) is said to be Hausdorff if given any two distinct points x, y \in X, there exists a neighborhood V of x and a neighborhood W of y such that $V \cap W = \varnothing$.\\
	 (In practice, most topological spaces one works with are Hausdorff; non-Hausdorff topological spaces tend to be so pathological that it is not very profitable to work with them.)
       - Remark: There is unfortunately no notion of a Cauchy sequence, a complete space, or a bounded space, for general topological spaces.
*** Chap 3 - Uniform Convergence
    1. Theorem /(Weierstrass M-test)/
       Let (X, d) be a metric space, and let $(f^{(n)})_{n=1}^\infty$ be a sequence of bounded real-valued continuous functions on X such that the series $\sum_{n=1}^\infty \|f^{(n)}\|_\infty$  is convergent. (Note that this is a series of plain old real numbers, not of functions.) Then the series $\sum_{n=1}^\infty \|f^{(n)}\|_\infty$ converges uniformly to some function f on X, and that function f is also continuous.\\
       /*Note:/ $\|f\|_\infty$ is the /sup norm/ or /uniform norm/.
    2. Uniform Approximation by Polynomials
       - Theorem /(Weierstrass approximation theorem)/
	 If [a, b] is an interval, f:[a, b] \to R is a continuous function, and \varepsilon > 0, then there exists a polynomial P on [a, b] such that $d_\infty(P, f ) \leq \varepsilon$ (i.e., $|P(x) − f(x)| \leq \varepsilon$ for all x \in [a, b]).
       - Remark: Another way of stating this theorem is as follows. Recall that C([a, b] \to R) was the space of continuous functions from [a, b] to R, with the uniform metric d_\infty. Let P([a, b] \to R) be the space of all polynomials on [a, b]; this is a subspace of C([a, b] \to R), since all polynomials are continuous. The Weierstrass approximation theorem then asserts that every continuous function is an adherent point of P([a, b] \to R); or in other words, that the closure of the space of polynomials is the space of continuous functions: $\overline{P([a, b] \to R)} = C([a, b] \to R)$.\\
	 In particular, every continuous function on [a, b] is the uniform limit of polynomials. Another way of saying this is that the space of polynomials is dense in the space of continuous functions, in the uniform topology.
       - Definition /(Compactly supported functions)/
	 Let [a, b] be an interval. A function f:R \to R is said to be supported on [a, b] if f(x) = 0 for all x \notin [a, b]. We say that f is compactly supported if it is supported on some interval [a, b]. If f is continuous and supported on [a, b], we define the improper integral $\int_{-\infty}^\infty f$ to be $\int_{-\infty}^\infty f := \int_{[a,b]} f$.
       - Definition /(Approximation to the identity)/
	 Let \varepsilon > 0 and 0 < \delta < 1. A function f : R \to R is said to be an (\varepsilon, \delta )-approximation to the identity if it obeys the following three properties:\\
	 (a) f is supported on [−1, 1], and f (x) \geq 0 for all −1 \leq x \leq 1.\\
	 (b) f is continuous, and $\int_{-\infty}^\infty f = 1$.\\
	 (c) |f(x)| \leq \varepsilon for all \delta \leq |x| \leq 1.
       - */Our proof of the Weierstrass approximation theorem relies on three key facts/*
       - *Fact 1* - /(Lemma - Polynomials can approximate the identity)/
	 For every \varepsilon > 0 and 0 < \delta < 1 there exists an (\varepsilon, \delta )-approximation to the identity which is a polynomial P on [−1, 1].
       - Definition /(Convolution)/
	 Let f : R \to R and g : R \to R be continuous, compactly supported functions. We define the convolution f∗g: R \to R of f and g to be the function $(f∗g)(x):= \int_{-\infty}^\infty f(y)g(x - y)dy$.
       - /(Basic properties of convolution)/
	 Let f: R \to R, g: R \to R,and h: R \to R be continuous, compactly supported functions. Then the following statements are true.\\
	 (a) The convolution f ∗ g is also a continuous, compactly supported function.\\
	 (b) (Convolution is commutative) We have f ∗ g = g ∗ f.\\
	 (c) (Convolution is linear) We have f ∗ (g + h) = f ∗ g + f ∗ h. Also, for any real number c, we have f ∗ (cg) = (cf ) ∗ g = c( f ∗ g).
       - *Fact 2* - /(Lema convolution with polynomials produces another polynomial)/:
	 Let f: R → R be a continuous function supported on [0, 1], and let g: R → R be a continuous function supported on [−1, 1] which is a polynomial on [−1, 1]. Then f ∗ g is a polynomial on [0, 1]. /(Note however that it may be non-polynomial outside of [0, 1].)/
       - *Fact 3*: /If one convolves a uniformly continuous function with an approximation to the identity, we obtain a new function which is close to the original function (which explains the terminology “approximation to the identity”)/\\
	 Lemma - Let f: R \to R be a continuous function supported on [0, 1], which is bounded by some M > 0 (i.e., |f(x)| \leq M for all x \in R), and let \varepsilon > 0 and 0 < \delta < 1 be such that one has |f(x)-f(y)| < \epsilon whenever x, y \in R and |x-y| < \delta . Let g be any (\varepsilon, \delta )-approximation to the identity. Then we have |f ∗ g(x) - f(x)| ≤ (1 + 4M)\varepsilon for all x \in [0, 1].
       - Corollary /(Weierstrass approximation theorem I)/
	 Let f: R \to R be a continuous function supported on [0, 1]. Then for every \varepsilon > 0, there exists a function P: R \to R which is polynomial on [0, 1] and such that |P(x) - f(x)| \leq \varepsilon for all x \in [0, 1].
       - Lemma /(the extension of f by zero)/:
	 Let f: [0, 1] \to R be a continuous function which equals 0 on the boundary of [0, 1], i.e., f(0) = f(1) = 0. Let F: R \to R be the function defined by setting F(x) := f(x) for x \in [0, 1] and F(x) := 0 for x \notin [0, 1]. Then F is also continuous.
       - Corollary /(Weierstrass approximation theorem II)/
	 Let f: [0, 1] \to R be a continuous function such that f(0) = f(1) = 0. Then for every \varepsilon > 0 there exists a polynomial P: [0, 1] \to R such that |P(x) - f(x)| \leq \varepsilon for all x \in [0, 1].
       - Corollary /(Weierstrass approximation theorem III)/
	 Let f: [0, 1] \to R be a continuous function. Then for every \varepsilon > 0 there exists a polynomial P: [0, 1] \to R such that |P(x) - f(x)| \leq \varepsilon for all x \in [0, 1].
       - /Proof of Theorem/
	 + Let f: [a, b] → R be a continuous function on [a, b]. Let g: [0, 1] \to R denote the function g(x):= f(a + (b − a)x) for all x \in  [0, 1].
	 + Observe then that f(y) = g((y − a)/(b − a)) for all y \in [a, b].
	 + The function g is continuous on [0, 1] (why?), and so by previous Corollary we may find a polynomial Q: [0, 1] \to R such that |Q(x) - g(x)| \leq \varepsilon for all x \in [0, 1]. In particular, for any y \in [a, b], we have
	 + |Q((y − a)/(b − a)) − g((y − a)/(b − a))| \leq \varepsilon
	 + If we thus set P(y):= Q((y − a)/(b − a)), then we observe that P is also a polynomial (why?), and so we have |P(y) − f(y)| \leq \varepsilon for all y \in [a, b], as desired.
       - /Remark 1/:
	 Note that the Weierstrass approximation theorem only works on bounded intervals [a, b]; continuous functions on R cannot be uniformly approximated by polynomials. For instance, the exponential function f: R → R defined by $f(x) := e^x$ cannot be approximated by any polynomial, because exponential functions grow faster than any polynomial and so there is no way one can even make the sup metric between f and a polynomial finite.
*** Chap 4 - Power series
    1. Real Analytic Functions
       - Definition /(Real analytic functions)/ Let E be a subset of R, and let f: E \to R be a function. If /a/ is an interior point of E, we say that f is /real analytic at a/ if there exists an open interval /(a − r, a + r)/ in E for some r > 0 such that there exists a power series $\sum_{n=0}^\infty c_n(x − a)^n$ centered at /a/ which has a radius of convergence greater than or equal to r and which converges to f on /(a − r, a + r)/. If E is an open set, and f is real analytic at every point a of E, we say that f is /real analytic on E/.
       - Example: Consider the function $f: R\backslash \{1\}$ to R defined by f(x):= 1/(1 − x). This function is real analytic at 0 because we have a power series $\sum_{n=0}^\infty x^n$ centered at 0 which converges to 1/(1 − x) = f(x) on the interval (−1, 1). This function is also real analytic at 2 because we have a power series $\sum_{n=0}^\infty (−1)^{n+1}(x − 2)^n$ which converges to $\frac{-1}{1−(-(x−2))} = \frac{1}{1-x} = f(x)$ on the interval (1, 3). In fact this function is real analytic on all of $R\backslash \{1\}$;
       - Corollary /(Taylor’s formula)/
	 Let E be a subset of R, let /a/ be an interior point of E, and let $f: E \to R$ be a function which is real analytic at a and has the power series expansion $f(x) = \sum_{n=0}^\infty c_n(x − a)^n$ for all x \in /(a − r, a + r)/ and some r > 0. Then for any integer k \geq 0, we have $f^{(k)}(a) = k!c_k$. In particular, we have /Taylor’s formula/ $f(x) = \sum_{n=0}^\infty \frac{f^{(n)}(a)}{n!} (x − a)^n$ for all x in /(a − r, a + r)./\\
	 /*Note:/Note that Taylor’s formula only works for functions which are real analytic; there are examples of functions which are infinitely differentiable but for which Taylor’s theorem fails. Another important corollary of Taylor’s formula is that a real analytic function
can have at most one power series at a point. While a real analytic function has a unique power series around any given point, it can certainly have different power series at different points.
*** Chap 5 - Fourier Series
    1. Periodic Functions
       - Definition:
	 Let L > 0 be a real number. A function $f: R \to C$ is periodic with period L, or L-periodic, if we have $f(x + L) = f(x)$ for every real number x.\\
	 Note: In particular, if a function f is 1-periodic, then we have f(x + k) = f(x) for every k \in Z. Because of this, 1-periodic functions are sometimes also called Z-periodic (and L-periodic functions called LZ-periodic).
       - Notation: The space of complex-valued continuous *Z*-periodic functions is denoted C(*R/Z;C*). (The notation *R/Z* comes from algebra, and denotes the quotient group of the additive group *R* by the additive group *Z*). By “continuous” we mean continuous at all points on *R*; merely being continuous on an interval such as [0, 1] will not suffice, as theremay be a discontinuity between the left and right limits at 1 (or at any other integer).
       - Lemma /(Basic properties of C(*R/Z;C*))/\\
	 (a) /(Boundedness)/ If f \in C(*R/Z;C*), then f is bounded.\\
	 (b) /(Vector space and algebra properties)/ If f, g \in C(*R/Z;C*), then the functions f + g, f − g, and f g are also in C(*R/Z;C*). Also, if c is any complex number, then the function cf is also in C(*R/Z;C*).\\
	 (c) /(Closure under uniform limits)/ If $(f_n)_{n=1}^\infty$ is a sequence of functions in C(*R/Z;C*) which converges uniformly to another function $f:R \to C$, then f is also in C(*R/Z;C*)
    2. Inner Products on Periodic Functions
       - Definition /(Inner product)/
	 If f, g \in C(*R/Z;C*), we define the inner produc $\langle f,g \rangle$ to be the quantity $\langle f,g \rangle  = \int_{[0,1]}f(x)\overline{g(x)}dx$.\\
	 Note:  In order to integrate a complex-valued function, $f(x) = g(x) + ih(x)$, we use the definition that $\int_{[a,b]}f:= \int_{[a,b]}g + i\int_{[a,b]}h$; i.e., we integrate the real and imaginary parts of the function separately.
       - Lemma: Let f, g, h \in C(*R/Z;C*).\\
	 (a) /(Hermitian property)/ We have $\langle g,f \rangle = \overline{\langle f,g \rangle}$.\\
	 (b) /(Positivity)/ We have $\langle f,f \rangle \geq 0$. Furthermore, we have $\langle f,f \rangle = 0$ if and only if f = 0 (i.e., f(x) = 0 for all x \in R).\\
	 (c) /(Linearity in the first variable)/ We have $\langle f + g, h \rangle = \langle f,h \rangle + \langle g,h \rangle$. For any complex number c, we have $\langle cf,g \rangle = c\langle f,g \rangle$.\\
	 (d) /(Antilinearity in the second variable)/ We have  $\langle f , g + h \rangle = \langle f,g \rangle + \langle f,h \rangle$. For any complex number c, we have $\langle cf,g \rangle = \overline{c}\langle f,g \rangle$.
       - Definition: /L^2 norm ||f||_2 of a function f \in C(*R/Z;C*)/
	 \[ \|f\|_2:=\sqrt{\langle f,f\rangle} = \left(\int_{[0,1]}f(x)\overline{f(x)}dx\right)^{1/2} = \left(\int_{[0,1]}|f(x)|^2 dx\right)^{1/2} \]
	 Thus ||f||_2 \geq 0 for all f . The norm ||f||_2 is sometimes called the /root mean square of f/.\\
	 *Remark: This $L^2$ norm isrelated to, but is distinctfrom, the $L^\infty$ norm $\|f\|_\infty := sup_{x\in R} |f(x)|$. For instance, if $f(x) = \sin{(2\pi x)}$, then $\|f\|_\infty = 1$ but $\|f\|_2 = \frac{1}{\sqrt{2}}$. In general, the best one can say is that $0 \leq \|f\|_2 \leq \|f\|_infty$.
       - Lema /(Some basic properties of the L^2 norm)/:
	 Let f, g \in C(*R/Z;C*).\\
	 (a) /(Non-degeneracy)/ We have $\|f\|_2 = 0$ if and only if $f=0$.\\
	 (b) /(Cauchy–Schwarz inequality)/ We have $|\langle f, g \rangle | \leq \| f\|_2 \|g\|_2$.\\
	 (c) /(Triangle inequality)/ We have $\|f + g\|_2 \leq \|f\|_2 + \|g\|_2$.\\
	 (d) /(Pythagoras’ theorem)/ If $\langle f,g \rangle = 0$, then \|f + g\|_2^2 = \|f\|_2^2 + \|g\|_2^2$. In light of Pythagoras’ theorem, we sometimes say that f and g are /orthogonal/.\\
	 (e) /(Homogeneity)/ We have $\|cf\|_2 = |c|\|f\|_2$ for all $c \in C$.
       - Definition /(L^2 metric d_{L^2} on C(*R/Z;C*)/
	 \[d_{L^2}(f,g):= \|f − g\|_2 = \left(\int_{[0,1]}|f(x) − g(x)|^2 dx\right)^{1/2}.\]
	 /The L^2 metric is very similar to the l^2 metric on Euclidean spaces Rn, which is why the notation is deliberately chosen to be similar./
       - Remark:\\
	 (a) Note that a sequence f_n of functions in C(*R/Z;C*) will converge in the L^2 metric to f \in C(*R/Z;C*) if $d_{L^2}(f_n,f) \to 0$ as $n \to \infty$, or in other words that $\lim_{n\to\infty}\int_{[0,1]}|f_n(x) − f(x)|^2 dx = 0$.\\
	 (b) The notion of convergence in L^2 metric is different from that of uniform or pointwise convergence.\\
	 (c) The L^2 metric is not as well-behaved as the $L^\infty$ metric. For instance, it turns out the space C(*R/Z;C*) is not complete in the L^2 metric, despite being complete in the $L^\infty$ metric.
    3. Trigonometric Polynomials
       - Definition /(Characters)/
	 For every integer n, we let /e_n/ \in C(*R/Z;C*) denote the function $e_n(x):=e^{2\pi inx}$. This is sometimes referred to as the /character with frequency n/.
       - Definition /(Trigonometric polynomials)/
	 A function $f$ in C(*R/Z;C*) is said to be a trigonometric polynomial if we can write $f=\sum_{n=-N}^N c_ne_n$ for some integer N \geq 0 and some complex numbers $(c_n)_{n=−N}^N$.
       - Lemma /(Characters are an orthonormal system)/
	 For any integers n and m, we have $\langle e_n, e_m \rangle = 1$ when n = m and $\langle e_n, e_m \rangle = 0$ when n \neq m. Also, we have $\|e_n\| = 1$.
       - Corollary:
	 Let $f = \sum_{n=−N}^N c_ne_n$ be a trigonometric polynomial. Then we have the formula $c_n = \langle f, e_n \rangle$ for all integers −N \leq n \leq N. Also, we have $0 = \langle f, e_n \rangle$ whenever n > N or n < −N. Also, we have the identity $\|f\|_2^2 = \sum_{n=−N}^N |c_n|^2$.
       - Definition /(Fourier transform)/
	 For any function $f$ \in C(*R/Z;R*), and any integer n \in Z, we define the $n^{th}$ /Fourier coefficient of $f$/ , denoted $\hat{f}(n)$, by the formula \[\hat{f}(n):= \langle f, e_n \rangle = \int_{[0,1]} f(x)e^{−2\pi inx} dx.\]
	 The function $\hat{f}: Z \to C$ is called the /Fourier transform of f/.
       - Note: in particular we have the /Fourier inversion formula/
	 \[f = \sum_{n=-\infty}^\infty \hat{f}(n)e_n\]
	 or in other words
	 \[f(x) = \sum_{n=−\infty}^\infty \hat{f}(n)e^{2\pi inx}.\]
	 The right-hand side is referred to as the /Fourier series of f/. Also, we have the /Plancherel formula/
	 \[\|f\|_2^2 = \sum_{n=-\infty}^\infty\|\hat{f}(n)\|^2.\]
	 + *Remark*: We stress that at present we have only proven the Fourier inversion and Plancherel formulae in the case when f is a trigonometric polynomial. Note that in this case that the Fourier coefficients $\hat{f}(n)$ are mostly zero (indeed, they can only be non-zero when −N \leq n \leq N), and so this infinite sum is really just a finite sum in disguise. In particular there are no issues about what sense the above series converge in; they both converge pointwise, uniformly, and in L^2 metric, since they are just finite sums.
       - /Now, we will extend the Fourier inversion and Plancherel formulae to general functions in C(R/Z; C), not just trigonometric polynomials. (It is also possible to extend the formula to discontinuous functions such as the square wave, but we will not do so here.)/
    4. Periodic Convolutions
       - Theorem /(Weierstrass approximation theoremfor trigonometric polynomials)/
	 Let $f$ \in C(*R/Z;C*), and let \varepsilon > 0. Then there exists a trigonometric polynomial $P$ such that $\|f − P\|_\infty \leq \varepsilon$.\\
	 /*Note 1:/ This theorem asserts that any continuous periodic function can be uniformly approximated by trigonometric polynomials. To put it another way, if we let P(*R/Z;C*) denote the space of all trigonometric polynomials, then the closure of P(*R/Z;C*) in the $L^\infty$ metric is C(*R/Z;C*).\\
	 /*Note 2:/ It is possible to prove this theorem directly from the Weierstrass approximation theorem for polynomials, and both theorems are a special case of a much more general theorem known as the /Stone-Weierstrass theorem/, which we will not discuss here. However we shall instead prove this theorem from scratch, in order to introduce a couple of interesting notions, notably that of periodic convolution.
       - Definition /(Periodic convolution)/
	 Let $f, g$ \in  C(*R/Z;C*). Then we define the /periodic convolution/ $f ∗ g: R \to C$ of $f$ and $g$ by the formula
	 \[f ∗ g(x):= \int_{[0,1]} f(y)g(x − y) dy.\]
	 /*Note:/ Note that this formula is slightly different from the convolution for compactly supported functions, because we are only integrating over [0, 1] and not on all of R. Thus, in principle we have given the symbol f ∗ g two conflicting meanings. However, in practice there will be no confusion, because it is not possible for a non-zero function to both be periodic and compactly supported.
       - Lemma /(Basic properties of periodic convolution)/
	 Let $f, g, h$ \in C(*R/Z;C*).\\
	 (a) /(Closure)/ The convolution f ∗ g is continuous and Z-periodic. In other words, $f ∗ g$ \in C(*R/Z;C*).\\
	 (b) /(Commutativity)/ We have $f ∗ g = g ∗ f$.\\
	 (c) /(Bilinearity)/ We have $f ∗ (g + h) = f ∗ g + f ∗ h$ and $( f + g) ∗ h = f ∗ h +g ∗ h$. For any complex number $c$, we have $c( f ∗ g) = (cf ) ∗ g = f ∗ (cg)$.
       - Definition /(Periodic approximation to the identity)/
	 Let \varepsilon > 0 and 0 < \delta < 1/2. A function $f$ \in C(*R/Z;C*) is said to be a /periodic $(\varepsilon, \delta)$ approximation to the identity/ if the following properties are true:\\
	 (a) $f(x) \geq 0$ for all $x \in R$, and $\int_{[0,1]}f = 1$.\\
	 (b) We have $f(x) < \varepsilon$ for all $\delta \leq |x| \leq 1 − \delta$.
       - Lemma:
	 For every \varepsilon > 0 and 0 < \delta < 1/2, there exists a trigonometric polynomial P which is an $(\varepsilon, \delta)$ approximation to the identity.
    5. The Fourier and Plancherel Theorems
       - Theorem /(Fourier theorem)/
	 For any f ∈ C(*R/Z;C*), the series $\sum_{n=−\infty}^\infty\hat{f}(n)e_n$ converges in L^2 metric to $f$ . In other words, we have
	 \[\lim_{n\to\infty}\|f − \sum_{n=-N}^N\hat{f}(n)e_n\|_2 = 0.\]
       - *Remark*:
	 Note that we have only obtained convergence of the Fourier series $\sum_{n=-\infty}^\infty\hat{f}(n)e_n$ to $f$ in the L^2 metric. One may ask whether one has convergence in the uniform or pointwise sense as well, but it turns out (perhaps somewhat surprisingly) that the answer is no to both of those questions. However, if one assumes that the function f is not only continuous, but is also differentiable, then one can recover pointwise convergence; if one assumes continuously differentiable, then one gets uniform convergence as well. These results are beyond the scope of this text and will not be proven here.
       - Theorem:
	 Let $f$ \in C(*R/Z;C*), and suppose that the series $\sum_{n=-\infty}^\infty|\hat{f}(n)|$ is absolutely convergent. Then the series $\sum_{n=-\infty}^\infty\hat{f}(n)e_n$ converges uniformly to $f$. In other words, we have
	 \[\lim_{n\to\infty} \| f − \sum_{n=-N}^N\hat{f}(n)e_n\|_\infty= 0.\]
       - Theorem /(Plancherel theorem or Parseval’s theorem)/
	 For any $f$ \in C(*R/Z;C*), the series $\sum_{n=−\infty}^\infty|\hat{f}(n)|^2$ is absolutely convergent, and
	 \[\|f\|_2^2 = \sum_{n=-\infty}^\infty |\hat{f}(n)|^2.\]
*** Chap 6 - Several Variable Differential Calculus
    1. Derivatives in Several Variable Calculus
       - Definition /(Differentiability)/
	 Let $E$ be a subset of $R^n, f: E \to R^m$ be a function, $x_0 \in E$ be a limit point of $E$, and let $L: R^n \to R^m$ be a linear transformation. We say that $f$ is differentiable at $x_0$ with derivative $L$ if we have
	 \[\lim_{x\to x_0;x\in E−\{x_0\}}\frac{\|f(x) - (f(x_0)+L(x-x-x_0))\|}{\|x-x_0\|} = 0 \]
	 Here $\|x\|$ is the length of $x$ (as measured in the l^2 metric):
	 \[\|(x_1, x_2, ... , x_n)\| = (x_1^2 + x_2^2 + .... + x-n^2)^{1/2}.\]
       - Lemma /(Uniqueness of derivatives)/
	 Let $E$ be a subset of $R^n, f: E \to R^m$ be a function, $x_0 \in E$ be an interior point of $E$, and let $L_1: R^n \to R^m$ and $L_2: R^n \to R^m$ be linear transformations. Suppose that $f$ is differentiable at $x_0$ with derivative $L_1$, and also differentiable at $x_0$ with derivative $L_2$. Then $L_1 = L_2$.
    2. Partial and Directional Derivatives
       - Definition /(Directional derivative)/
	 Let $E$ be a subset of $R^n, f: E \to R^m$ be a function, let $x_0$ be an interior point of $E$, and let $v$ be a vector in $R^n$. If the limit
	 \[\lim_{t\to 0;t>0,x_0+tv\in E}\frac{f(x_0 + tv) − f(x_0)}{t}\]
	 exists, we say that $f$ is differentiable in the direction $v$ at $x_0$, and we denote the above limit by $D_vf(x_0)$:
	 \[ D_vf(x_0):= \lim_{t\to 0;t>0} \frac{f(x_0 + tv) − f(x_0)}{t}.\]
	 *Remark*: Note that we are dividing by a scalar $t$, rather than a vector, so this definition makes sense, and $D_vf(x_0)$ will be a vector in $R^m$. It is sometimes possible to also define directional derivatives on the boundary of $E$, if the vector $v$ is pointing in an “inward” direction (this generalizes the notion of left derivatives and right derivatives from singlevariable calculus); but we will not pursue these matters here.
       - Lemma:
	 Let $E$ be a subset of $R^n, f: E \to R^m$ be a function, $x_0$ be an interior point of $E$, and let $v$ be a vector in $R^n$. If $f$ is differentiable at $x_0$, then $f$ is also differentiable in the direction $v$ at $x_0$, and $D_vf(x_0)=f'(x_0)v$.\\
	 /*Note: One consequence of this lemma is that total differentiability implies directional differentiability. However, the converse is not true/
       - Definition /(Partial derivative)/
	 Let $E$ be a subset of $R^n$, let $f: E \to R^m$ be a function, let $x_0$ be an interior point of $E$, and let $1 \leq j \leq n$. Then the partial derivative of $f$ with respect to the $x_j$ variable at $x_0$, denoted $\frac{\partial f}{\partial x_j}(x_0)$, is defined by
	 \[\frac{\partial f}{\partial x_j}(x_0):= \lim_{t\to 0;t\neq 0,x_0+te_j\in E} \frac{f(x_0 + te_j) − f(x_0)}{t} = \frac{d}{dt} f(x_0 + te_j)\vert_{t=0} \]
	 provided of course that the limit exists. (If the limit does not exist, we leave $\frac{\partial f}{\partial x_j}(x_0)$ undefined.)\\
	 We say that $f$ is /continuously differentiable/ if the partial derivatives $\frac{\partial f}{\partial x_1}, ..., \frac{\partial f}{\partial x_n}$  exist and are continuous on $E$.\\
	 Informally, the partial derivative can be obtained by holding all the variables other than $x_j$ fixed and then applying the single-variable calculus derivative in the $x_j$ variable. Note that if $f$ takes values in $R^m$, then so will $\frac{\partial f}{\partial x_j}$. Indeed, if we write $f$ in components as $f = (f_1,... , f_m)$, it is easy to see that
	 \[ \frac{\partial f}{\partial x_j} (x_0) = \left( \frac{\partial f_1}{\partial x_1}(x_0), ..., \frac{\partial f_m}{\partial x_j}(x_0)\right),\]
	 i.e., to differentiate a vector-valued function one just has to differentiate each of the components separately.
       - Theorem:
	 Let $E$ be a subset of $R^n, f: E to R^m$ be a function, $F$ be a subset of $E$, and $x_0$ be an interior point of $F$. If all the partial derivatives $\frac{\partial f}{\partial x_j}$ exist on $F$ and are continuous at $x_0$, then $f$ is differentiable at $x_0$, and the linear transformation $f'(x0): R^n \to R^m$ is defined by
	 \[f'(x_0)(v_j)_{1\leq j\leq n} = \sum_{j=1}^n \frac{\partial f}{\partial x_j} (x0).\]
       - Remark:
	 If the partial derivatives of a function $f: E \to R^m$ exist and are continuous on some set $F$, then all the directional derivatives also exist at every interior point $x_0$ of $F$, and we have the formula
	 \[D_{(v_1,...,v_n)}f(x_0) = \sum_{j=1}^n v_j \frac{\partial f}{\partial x_j}(x_0).\]
	 In particular, if $f: E \to R$ is a real-valued function, and we define the */gradient/* $\nabla f(x_0)$ of $f$ at $x_0$ to be the n-dimensional row vector $\nabla f(x_0):=(\frac{\partial f}{\partial x_1} (x_0),... , \frac{\partial f}{\partial x_n} (x_0))$, then we have the familiar formula
	 \[D_v f(x_0) = v.\nabla f(x_0)\]
	 whenever $x_0$ is in the interior of the region where the gradient exists and is continuous.
    3. Double Derivatives and Clairaut’s Theorem
       - Definition /(Twice continuous differentiability)/
	 Let $E$ be an open subset of $R^n$, and let $f: E \to R^m$ be a function. We say that $f$ is twice continuously differentiable if it is continuously differentiable, and the partial derivatives $\frac{\partial f}{\partial x_1}, ... , \frac{\partial f}{\partial x_n}$ are themselves continuously differentiable.
       - Theorem /(Clairaut’s theorem)/
	 Let $E$ be an open subset of $R^n$, and let $f: E \to R^m$ be a twice continuously differentiable function on $E$. Then we have $\frac{\partial f}{\partial x_j}\frac{\partial f}{\partial x_i}(x_0) =\frac{\partial f}{\partial x_i}\frac{\partial f}{\partial x_j}(x_0)$ for all $1 \leq i, j \leq n$.
    4. The Contraction Mapping Theorem
       - Definition /(Contraction)/
	 /Let (X, d) be a metric space, and let f: X \to X be a map. We say that f is a contraction if we have d(f(x), f(y)) \leq d(x, y) for all x, y \in X. We say that f is a strict contraction if there exists a constant 0 < c < 1 such that d(f(x), f(y)) \leq cd(x, y) for all x, y \in X ; we call c the contraction constant of f./
       - Definition /(Fixed points)/
	 Let f: X \to X be a map, and x \in X . We say that x is a fixed point of f if f(x) = x.\\
	 *Note: Contractions do not necessarily have any fixed points; for instance, the map f: R \to R defined by f(x) = x + 1 does not. However, it turns out that strict contractions always do, at least when X is complete.
       - Theorem /(Contraction mapping theorem)/
	 /Let (X, d) be a metric space, and let f: X \to X be a strict contraction. Then f can have at most one fixed point. Moreover, if we also assume that X is non-empty and complete, then f has exactly one fixed point./
       - Remark: We shall give one consequence of the contraction mapping theorem which is important for our application to the inverse function theorem. Basically, this says that any map f on a ball which is a “small” perturbation of the identity map, remains one-to-one and cannot create any internal holes in the ball.
       - Lemma:
	 Let B(0, r) be a ball in R^n centered at the origin, and let g: B(0, r) \to R^n be a map such that g(0) = 0 and ||g(x) − g(y)|| \leq 1/2||x − y|| for all x, y \in B(0, r) (here ||x|| denotes the length of x in R^n). Then the function f: B(0, r) \to R^n defined by f(x):= x + g(x) is one-to-one, and furthermore the image f(B(0, r)) of this map contains the ball B(0, r/2).
    5. The Inverse Function Theorem in Several Variable Calculus
       - Theorem /(Inverse function theorem)/
	 Let $E$ be an open subset of $R^n$, and let $f: E \to R^n$ be a function which is continuously differentiable on $E$. Suppose $x_0 \in E$ is such that the linear transformation $f'(x_0) : R^n to R^n$ is invertible. Then there exists an open set $U$ in $E$ containing $x_0$, and an open set $V$ in $R^n$ containing $f(x_0)$, such that $f$ is a bijection from $U$ to $V$. In particular, there is an inverse map $f^{−1} : V \to U$. Furthermore, this inverse map is differentiable at $f(x_0)$, and
	 \[(f^{−1})'(f(x_0)) = (f'(x_0))^{-1}.\]
    6. The Implicit Function Theorem
       - Theorem /(Implicit function theorem)/
	 Let $E$ be an open subset of $R^n$, let $f: E \to R$ be continuously differentiable, and let $y = (y_1,... , y_n)$ be a point in $E$ such that $f(y) = 0$ and $\frac{\partial f}{\partial x_n}(y) \neq 0$. Then there exists an open subset $U$ of $R^{n−1}$ containing $(y_1,... , y_{n−1})$, an open subset $V$ of $E$ containing $y$, and a function $g: U \to R$ such that $g(y_1,... , y_{n−1}) = y_n$, and
	 \[\{(x_1,... , x_n) \in V : f(x_1,... , x_n) = 0\}\]
	 \[= \{(x_1,... , x_{n−1}, g(x_1,... , x_{n−1})) : (x_1,... , x_{n−1}) \in U\}.\]
	 In other words, the set $\{x \in V : f(x) = 0\}$ is a graph of a function over $U$. Moreover, $g$ is differentiable at $(y_1,... , y_{n−1})$, and we have
	 \[\frac{\partial g}{\partial x_j}(y_1,... , y_{n−1}) = −\frac{\partial g}{\partial x_j}(y)/\frac{\partial g}{\partial x_n}(y) \]
	 for all $1 \leq j \leq n − 1$.
       - Remark:
	 Sets which look like graphs of continuous functions at every point have a name, they are called /manifolds/. Thus $\{x \in R^n : f(x) = 0\}$ will be a manifold if it contains no critical points of $f$ . The theory of manifolds is very important in modern geometry (especially differential geometry and algebraic geometry), but we will not discuss it here as it is a graduate level topic.
*** Chap 7 - Lebesgue Measure
    1. Outer Measure
       - Definition /(Open box)/
	 An open box (or box for short) $B$ in $R^n$ is any set of the form
	 \[B = \prod_{i=1}^n (a_i, b_i) := \{(x_1,... , x_n) \in R^n: x_i \in (a_i, b_i) \text{ for all } 1 \leq i \leq n\},\]
	 where $b_i \geq a_i$ are real numbers. We define the volume $vol(B)$ of this box to be the number
	 \[vol(B) := \prod_{i=1}^n (b_i − a_i) = (b_1 − a_1)(b_2 − a_2)...(b_n − a_n).\]
       - Definition /(Covering by boxes)/
	 Let $\Omega \subseteq R^n$ be a subset of $R^n$. We say that a collection $(B_j)_{j\in J}$ of boxes cover $\Omega$ iff $\Omega \subseteq \bigcup_{j\in J} B_j$.
       - Definition /(Outer measure)/
	 If $\Omega$ is a set, we define the outer measure $m^∗(\Omega )$ of $\Omega$ to be the quantity
	 \[m^∗(\Omega ) := \inf \left\{\sum_{j\in J} vol(B_j): (B_j)_{j\in J} \text{ covers $\Omega$ ; J at most countable } \right\}\]
    2. Outer Measure Is not Additive
       - Proposition /(Failure of countable additivity)/
	 There exists a countable collection $(A_j)_{j\in J}$ of disjoint subsets of $R$, such that $m^∗(\bigcup_{j\in J}A_j) \neq \sum_{j\in J}m^∗(A_j)$.\\
	 *Remark*: /The proof used the axiom of choice. This turns out to be absolutely necessary; one can prove using some advanced techniques in mathematical logic that if one does not assume the axiom of choice, then it is possible to have a mathematical model where outer measure is countably additive./
       - Proposition /(Failure of finite additivity)/
	 There exists a finite collection $(A_j)_{j\in J}$ of disjoint subsets of $R$, such that
	 \[m^∗\left( \bigcup_{j\in J} A_j\right) \neq \sum_{j\in J}m^∗(A_j).\]
    3. Measurable Sets
       - Definition /(Lebesgue measurability)/
	 Let $E$ be a subset of $R^n$. We say that $E$ is /Lebesgue measurable/, or /measurable/ for short, iff we have the identity
	 \[m^∗(A) = m^∗(A \cap E) + m^∗(A \backslash E)\]
	 for every subset $A$ of $R^n$. If $E$ is measurable, we define the /Lebesgue measure/ of $E$ to be $m(E) = m^∗(E)$; if $E$ is not measurable, we leave $m(E)$ undefined.
       - Lemma /(Half-spaces are measurable)/
	 The half-space ${(x_1,... , x_n) \in R^n : x_n > 0}$ is measurable.
       - Lemma /(Properties of measurable sets)/\\
	 (a) If $E$ is measurable, then $R^n\backslash E$ is also measurable.\\
	 (b) (Translation invariance) If $E$ is measurable, and $x \in R^n$, then $x + E$ is also measurable, and $m(x + E) = m(E)$.\\
	 (c) If $E_1$ and $E_2$ are measurable, then $E_1 \cap E_2$ and $E_1 \cup E_2$ are measurable.\\
	 (d) (Boolean algebra property) If $E_1, E_2,... ,E_ N$ are measurable, then $\bigcup_{j=1}^N E_ j$ and $\bigcap_{j=1}^N E_j$ are measurable.\\
	 (e) Every open box, and every closed box, is measurable.\\
	 (f) Any set $E$ of outer measure zero (i.e., $m^∗(E) = 0$) is measurable.
       - Lemma /(Finite additivity)/
	 If $(E_j)_{j\in J}$ are a finite collection of disjoint measurable sets, then for any set $A$ (not necessarily measurable), we have
	 \[m^*\left( A \cap\bigcup_{j\in J}E_j\right) = \sum_{j\in J} m^∗(A \cap E_j).\]
	 Furthermore, we have $m\left(\bigcup_{j\in J} E_j\right) = \sum_{j\in J} m(E_j)$.
       - Corollary: If $A \subseteq B$ are two measurable sets, then $B\backslash A$ is also measurable, and $m(B\backslash A) + m(A) = m(B)$.
       - Lemma /(Countable additivity)/
	 If $(E_j)_{j\in J}$ are a countable collection of disjoint measurable sets, then $\bigcup_{j\in J} E_j$ is measurable, and $m\left(\bigcup_{j\in J} E_j\right) = \sum_{j\in J} m(E_j)$.
       - Lemma /(\sigma -algebra property)/
	 If $(\Omega_j)_{j\in J}$ are any countable collection of measurable sets (so $J$ is countable), then the union$\bigcup_{j\in J}\Omega_j$ and the intersection $\bigcap_{j\in J}\Omega_j$ are also measurable.
       - Lemma: Every open set can be written as a countable or finite union of open boxes.
       - Lemma /(Borel property)/ Every open set, and every closed set, is Lebesgue measurable.
    4. Measurable Functions
       - Definition /(Measurable functions)/
	 Let $\Omega$ be a measurable subset of $R^n$, and let $f:\Omega \to  R^m$ be a function. A function $f$ is measurable iff $f^{−1}(V)$ is measurable for every open set $V \subseteq R^m$.\\
	 /*Remark: most sets that we deal with in real life are measurable, so it is only natural to learn that most functions we deal with in real life are also measurable./
       - *Retrive* /(inverse images)/:
	 If U is a subset of Y, we define the set $f^{−1}(U)$ to be the set\\
	 $f^{−1}(U) := \{x \in X : f(x) \in U\}$.\\
	 In other words, $f^{−1}(U)$ consists of all the elements of X which map into U: $f(x) \in U <=> x \in f^{−1}(U)$. We call $f^{−1}(U)$ the inverse image of U.\\
	 *Example: If f: Z \to Z is the map f(x) = x^2, then $f^{−1}(\{0, 1, 4\}) = \{−2, −1, 0, 1, 2\}$. \\
	 /Note that f does not have to be invertible in order for $f^{−1}(U)$ to make sense/. Also /note that images and inverse images do not quite invert each other/, for instance we have $f^{−1}(f(\{−1, 0, 1, 2\})) \neq \{−1, 0, 1, 2\}$.
       - Lemma /(Continuous functions are measurable)/
	 Let $\Omega$ be a measurable subset of $R^n$, and let $f: \Omega \to R^m$ be continuous. Then $f$ is also measurable.
       - Lemma:
	 Let $\Omega$ be a measurable subset of $R^n$, and let $f: \Omega \to  R^m$ be a function. Then $f$ is measurable if and only if $f^{−1}(B)$ is measurable for every open box $B$.
       - Corollary:
	 Let $\Omega$ be a measurable subset of $R^n$, and let $f:\Omega \to R^m$ be a function. Suppose that $f = (f_1,... , f_m)$, where $f_j:\Omega \to R$ is the /jth/ co-ordinate of $f$. Then $f$ is measurable if and only if all of the $f_j$ are individually measurable.
       - Remark:
	 /Unfortunately, it is not true that the composition of two measurable functions is automatically measurable; however we can do the next best thing: a continuous function applied to a measurable function is measurable./
       - Lemma:
	 Let $\Omega$ be a measurable subset of $R^n$, and let $W$ be an open subset of $R^m$. If $f:\Omega \to W$ is measurable, and $g: W \to R^p$ is continuous, then $g\circ f : \Omega \to R^p$ is measurable.
       - Corollary:
	 Let $\Omega$  be a measurable subset of $R^n$. If $f:\Omega \to R$ is a measurable function, then so is $|f|$, $\max(f,0)$, and $\min(f,0)$.
       - Corollary:
	 Let $\Omega$  be a measurable subset of $R^n$. If $f:\Omega \to R$ and $g:\Omega \to R$ are measurable functions, then so is $f + g, f − g, fg, \max(f, g), \min( f, g)$. If $g(x) \neq 0$ for all $x \in \Omega$ , then $f/g$ is also measurable.
       - Lemma:
	 Let $\Omega$  be a measurable subset of $R^n$, and let $f: \Omega \to R$ be a function. Then $f$ is measurable if and only if $f^{−1}((a, \infty))$ is measurable for every real number $a$.
       - Definition /(Measurable functions in the extended reals)/
	 Let $\Omega$  be a measurable subset of $R^n$. A function $f: \Omega \to R^*$ is said to be measureable iff $f^{−1}((a,+\infty])$ is measurable for every real number $a$.
       - Lemma /(Limits of measurable functions are measurable)/
	 Let $\Omega$  be a measurable subset of $R^n$. For each positive integer $n$, let $f_n :|Omega \to R^∗$ be a measurable function. Then the functions $\sup_{n\geq 1} f_n$, $\inf_{n\geq 1}f_n$, $\limsup_{n\to\infty} f_n$, and $\liminf_{n\to\infty} f_n$ are also measurable. In particular, if the $f_n$ converge pointwise to another function $f :\Omega \to R^∗$, then $f$ is also measurable.
       - /Note: As you can see, just about anything one does to a measurable function will produce another measurable function. This is basically why almost every function one deals with in mathematics is measurable. (Indeed, the only way to construct nonmeasurable functions is via artificial means such as invoking the axiom of choice.)/
*** Chap 8 - Lebesgue integration
    1. Simple Functions
       - Definition /(Simple functions)/
	 Let $\Omega$ be a measurable subset of $R^n$, and let $f:\Omega \to R$ be a measurable function. We say that $f$ is a /simple function/ if the image $f(\Omega)$ is finite. In other words, there exists a finite number of real numbers $c_1, c_2,... , c_N$ such that for every $x \in \Omega$ , we have $f(x) = c_j$ for some $1 \leq j \leq N$.
       - Definition /(the characteristic function)/
	 $\chi_E : \Omega \to R$ by setting $\chi_E(x):=1$ if $x \in E$, and $\chi_E(x):=0$ if $x \notin E$. (In some texts, $\chi_E$ is also written $1_E$ and is referred to as an /indicator function/.)
       - /Remark:/
	 Three basic properties of simple functions: they form a vector space, that they are linear combinations of /characteristic functions/, and that they approximate measurable functions.
       - Definition /(Lebesgue integral of simple functions)/
	 Let $\Omega$ be a measurable subset of $R^n$, and let $f: \Omega \to R$ be a simple function which is non-negative; thus $f$ is measurable and the image $f(\Omega)$ is finite and contained in $[0, \infty )$. We then define the /Lebesgue integral/ $\int_{\Omega}f$ of $f$ on $\Omega$ by
	 \[\int_{\Omega}f := \sum_{\lambda \in f(\Omega);\lambda >0} \lambda m(\{x \in \Omega : f(x) = \lambda\}).\]
	 We will also sometimes write $\int_{\Omega}f$ as $\int_{\Omega}fdm$ (to emphasize the rôle of Lebesgue measure m) or use a dummy variable such as $x$, e.g., $\int_{\Omega}f(x)dx$.
       - /Notational convention:/
	 if a property P(x) holds for all points in \Omega, except for a set of measure zero, then we say that P holds for almost every point in \Omega.
    2. Integration of Non-negative Measurable Functions
       - Definition /(Majorization)/
	 Let $f:\Omega \to R$ and $g:\Omega \to R$ be functions. We say that $f$ majorizes $g$, or $g$ minorizes $f$, if we have $f(x) \geq g(x)$ for all $x \in \Omega$.\\
	 We sometimes use the phrase "f dominates g" instead of "f majorizes g".
       - Definition /(Lebesgue integral for non-negative functions)/
	 Let $\Omega$ be a measurable subset of $R^n$, and let $f :\Omega \to [0,\infty ]$ be measurable and non-negative. Then we define the /Lebesgue integral/ $\int_{\Omega}f$ of $f$ on $\Omega$ to be
	 \[ \int_\Omega f := \sup \left\{ \int_\Omega s : s \text{ is simple and non-negative, and minorizes }f \right\} . \]
	 /*Remark: The reader should compare this notion to that of a lower Riemann integral. Interestingly, we will not need to match this lower integral with an upper integral here./
       - Proposition
	 Let $\Omega$  be a measurable set, and let $f:\Omega \to [0, \infty ]$ and $g: \Omega \to [0, \infty ]$ be non-negative measurable functions.\\
	 (a) We have $0 \leq \int_\Omega f \leq \infty$. Furthermore, we have $\int_\Omega f = 0$ if and only if $f(x) = 0$ for almost every $x \in \Omega$ .\\
	 (b) For any positive number $c$, we have $\int_\Omega cf = c\int_\Omega f$.\\
	 (c) If $f(x) \leq g(x)$ for all $x \in\Omega$, then we have $\int_\Omega f \leq \int_\Omega g$.\\
	 (d) If $f(x) = g(x)$ for almost every $x \in \Omega$, then $\int_\Omega f = \int_\Omega g$.\\
	 (e) If $\Omega' \subseteq \Omega$ is measurable, then $\int_{\Omega'} f = \int_\Omega f\chi_{\Omega'} \leq \int_\Omega f$.
       - Lemma /(Interchange of addition and integration)/
	 Let $\Omega$  be a measurable subset of $R^n$, and let $f :\Omega \to [0, \infty ]$ and $g:\Omega \to [0, \infty ]$ be measurable functions. Then $\int_\Omega (f + g) = \int_\Omega f + \int_\Omega g$.
    3. Integration of Absolutely Integrable Functions
       - Definition /(Absolutely integrable functions)/
	 Let $\Omega$ be a measurable subset of $R^n$. A measurable function $f : \Omega \to R^∗$ is said to be absolutely integrable if the integral $\int_\Omega |f|$ is finite.\\
	 Of course, $|f|$ is always non-negative, so this definition makes sense even if $f$ changes sign. Absolutely integrable functions are also known as $L^1(\Omega )$ functions.\\
	 If $f :\Omega \to R^∗$ is a function, we define the positive part $f^+:\Omega \to [0, \infty ]$ and negative part $f^− :\Omega \to [0, \infty ]$ by the formulae $f^+:= \max( f, 0); f^−:= − \min( f, 0)$.
       - Definition /(Lebesgue integral)/ Let $f :\Omega \to R^∗$ be an absolutely integrable function. We define the /Lebesgue integral/ $\int_\Omega f$ of $f$ to be the quantity
	 \[\int_\Omega f:= \int_\Omega f^+ - \int_\Omega f^- .\]
       - Proposition:
	 Let \Omega be a measurable set, and let $f :\Omega \to R$ and g :\Omega \to R$ be /absolutely integrable functions/.\\
	 (a) For any real number c (positive, zero, or negative), we have that cf is absolutely integrable and \int_\Omega cf = c\int_\Omega f.\\
	 (b) The function f + g is absolutely integrable, and \int_\Omega (f + g) = \int_\Omega f + \int_\Omega g.\\
	 (c) If f(x) \leq g(x) for all x \in \Omega , then we have \int_\Omega f \leq \int_\Omega g.\\
	 (d) If f(x) = g(x) for almost every x \in \Omega , then \int_\Omega f = \int_\Omega g.
       - Theorem /(Lebesgue dominated convergence theorem)/
	 Let \Omega  be a measurable subset of $R^n$, and let f_1, f_2,... be a sequence of measurable functions from \Omega to R^∗ which /converge pointwise/. Suppose also that there is an absolutely integrable function F:\Omega  \to [0, \infty ] such that |f_n(x)| \leq F(x)for all x \in \Omega and all n = 1, 2, 3,... . Then
	 \[ \int_\Omega \lim_{n\to\infty} f_n = \lim_{n\to\infty}\int_\Omega f_n.\]
       - Definition /(Upper and lower Lebesgue integral)/
	 Let \Omega be ameasurable subset of R^n, and let f: \Omega \to R be a function /(not necessarily measurable)/. We define the /upper Lebesgue integral/ $\overline{\int_\Omega} f$ to be
	 \[\overline{\int_\Omega}f := \inf \left\{\int_\Omega g: g \text{ is an absolutely integrable function from $\Omega$ to R that majorizes f} \right\}\]
	 and the /lower Lebesgue integral/ $\underline{\int_\Omega} f$ to be
	 \[\underline{\int_\Omega} f:= \sup\left\{g : g \text{ is an absolutely integrable function from $\Omega$ to R that minorizes f}\right\}.\]
	 - Lemma:
	 Let \Omega be a measurable subset of R^n, and let f : \Omega \to R be a function /(not necessarily measurable)/. Let A be a real number, and suppose $\overline{\int_\Omega}f = \underline{\int_\Omega} f = A$. Then f is absolutely integrable, and
	 \[\int_\Omega f = \overline{\int_\Omega}f = \underline{\int_\Omega} f = A. \]
    4. Comparison with the Riemann Integral
       - *Remark*: /every Riemann integrable function is also Lebesgue integrable, at least on bounded intervals. However, the converse is not true. Take for instance the function f: [0, 1] \to R defined by f(x):=1 when x is rational, and f(x):=0 when x is irrational. we know that f is not Riemann integrable. On the other hand, f is the characteristic function of the set Q \cap [0, 1], which is countable and hence measure zero. Thus f is Lebesgue integrable and $\int_{[0,1]} f = 0$. Thus the Lebesgue integral can handle more functions than the Riemann integral; this is one of the primary reasons why we use the Lebesgue integral in analysis. The other reason is that the Lebesgue integral interacts well with limits, as the Lebesgue monotone convergence theorem, Fatou’s lemma, and Lebesgue dominated convergence theorem already attest. There are no comparable theorems for the Riemann integral./
    5. Fubini’s Theorem
       - Theorem /(Fubini’s theorem)/
	 Let f: R^2 \to R be an absolutely integrable function. Then there exists absolutely integrable functions F: R \to R and G: R \to R such that for almost every x, f(x, y) is absolutely integrable in y with
	 \[F(x) = \int_R f(x, y)dy,\]
	 and for almost every y, f(x, y) is absolutely integrable in x with
	 \[G(y) = \int_R f(x, y)dx.\]
	 Finally, we have
	 \[\int_R F(x)dx = \int_{R^2} f = \int_{R^2}G(y)dy.\]
       - Remark:
	 Very roughly speaking, Fubini’s theorem says that
	 \[\int_R\left(\int_R f(x, y)dy\right)dx = \int_{R^2} f = \int_R\left(\int_R f(x, y)dx\right) dy.\]
	 This allows us to compute two-dimensional integrals by splitting them into two onedimensional integrals. The reason why we do not write Fubini’s theorem this way, though, is that it is possible that the integral $\int_R f(x, y)dy$ does not actually exist for every x, and similarly $\int_R f(x, y)dx$ does not exist for every y; Fubini’s theorem only asserts that these integrals only exist for /almost every/ x and y. For instance, if f(x, y) is the function which equals 1 when y > 0 and x = 0, equals −1 when y < 0 and x = 0, and is zero otherwise, then f is absolutely integrable on R^2 and $\int_{R^2} f = 0$ (since f equals zero almost everywhere in R^2), but $\int_R f(x, y)dy$ is not absolutely integrable when x = 0 (though it is absolutely integrable for every other
x).
* Functional analysis
** Introductory functional analysis with application - Kreyzig
*** Chap 1 - Metric spaces
    1. Metric space
       - /Sequence space $l^\infty$/:
	 We take the set $X$ of all /bounded sequences/ of complex numbers and define the metric by
	 \[d(x,y) =  \sup_{j\in N}|x_j-y_j|; x, y \in X\]
	 $l^\infty$ is a /sequence space/ because each element of $X$ (each point of $X$) is a sequence.
       - Definition /(Dense set, separable space)/
	 A subset $M$ of a metric space $X$ is said to be /dense/ in $X$ if
	 \[\overline{M}=X.\]
	 $X$ is said to be /separable/ if it has a /countable subset/ which is dense in $X$.\\
	 Hence if $M$ is dense in $X$, then every ball in $X$, no matter how small, will contain points of $M$; or, in other words, in this case there is no point $x \in X$ which has a neighborhood that does not contain points of $M$.\\
	 *Example:\\
	 (i) *Real line R*. /The real line *R* is separable/.\\
	 (ii) *Complex plane C*. /The complex plane *C* is separable/.\\
	 (iii) *Discrete metric space*. /A discrete metric space X is separable if and only if X is countable./ \\
	 (iv) *Space $l^\infty$*. /The space $l^\infty$ is not separable./\\
	 (v) *Space $l^p$*. /The space $l^p$ with $1 \leq p \leq +\infty$ is separable./
       - Definition /(Isometric mapping, isometric spaces)/.
	 Let X = (X, d) and X' =(X', d') be metric spaces. Then:\\
	 (a) /A mapping T/ of X into X' is said to be /isometric/ or an /isometry/ if T preserves distances, that is, if for all x, y \in X, d'(Tx, Ty) = d(x, y), where Tx and Ty are the images of x and y, respectively.\\
	 (b) /The space X/ is said to be /isometric/ with the space X' if there exists a /bijective isometry/ of X onto X'. The spaces X and X' are then called /isometric spaces/.\\
	 /Hence isometric spaces may differ at most by the nature of their points but are indistinguishable from the viewpoint of metric. And in any study in which the nature of the points does not matter, we may regard the two spaces as identical-as two copies of the same "abstract" space./
       - Theorem /(Completion 1)/.
	 For a metric space X = (X, d) there exists a complete metric space X' = (X', d') which has a subspace W that is isometric with X and is dense in X'. This space X' is unique except for isometries, that is, if X'' is any complete metric space having a dense subspace W' isometric with X, then X'' and X' are isometric.
       - Definition /(Homeomorphism)/
	 A homeomorphism is a /continuous bijective mapping/ T: X \to Y /whose inverse is continuous/; the metric spaces X and Y are then said to be /homeomorphic/.\\
	 (a) If X and Y are isometric, they are homeomorphic.
	 (b) A complete and an incomplete metric space may be homeomorphic. (ex: (0,1) and *R*).
*** Chap 2 - Normed spaces and Banach spaces
    1. Vector space
       - Definition /(Quotient space, codimension)/
	 Let Y be a subspace of a vector space X. The /coset/ of an element x \in X with respect to Y is denoted by x + Y and is defined to be the set
	 \[ x+Y = \{v | v = x+y,y \in Y\}.\]
	 /*Lema/: The distinct cosets form a partition of X. Under algebraic operations defined by
	 \[ (w + Y)+(x + Y)=(w+x)+ Y; \alpha(x+y)=\alpha x + Y\]
	 these cosets constitute the elements of a vector space. This space is called the /quotient space/ (or sometimes /factor space/) of X by Y (or /modulo/ Y) and is denoted by X/Y. Its dimension is called the /codimension/ of Y and is denoted by codim Y, that is,
	 \[\text{codim }Y = \dim(X/Y).\]
    2. Normed space. Banach space
       - Motivation:
	 /in many cases a vector space X may at the same time be a metric space because a metric d is defined on X. However, if there is no relation between the algebraic structure and the metric, we cannot expect a useful and applicable theory that combines algebraic and metric concepts. To guarantee such a relation between "algebraic" and "geometric" properties of X we define on X a metric d in a special way as follows. We first introduce an auxiliary concept, the norm (definition below), which uses the algebraic operations of vector space. Then we employ the norm to obtain a metric d that is of the desired kind. This idea leads to the concept of a normed space. It turns out that normed spaces are special enough to provide a basis for a rich and interesting theory, but general enough to include many concrete models of practical importance. In fact, a large number of metric spaces in analysis can be regarded as normed spaces, so that a normed space is probably the most important kind of space in functional analysis, at least from the viewpoint of present-day applications./
       - Definition /(Normed space, Banach space)/.
	 A /normed space/ X is a vector space with a norm defined on it. A /Banach space/ is a complete normed space (complete in the metric defined by the norm). Here a *norm* on a (real or complex) vector space X is a real-valued function on X whose value at an $x \in  X$ is denoted by $\|x\|$ and which has the properties: \\
	 (Nl) $\|x\| \geq 0$ \\
	 (N2) $\|x\| = 0 <=> x = 0$ \\
	 (N3) $\|\alpha x\| = |\alpha |\|x\|$ \\
	 (N4) $\|x+y\| \leq \|x\| + \|y\|$ \\
	 here x and y are arbitrary vectors in X and \alpha is any scalar. A norm on X defines a metric d on X which is given by
	 \[ \textbf{(1)	} d(x, y) = \|x - y\|;  (x, y \in X) \]
	 and is called the /metric induced by the norm/. The normed space just defined is denoted by $(X, \|\cdot \|)$ or simply by $X$.
       - Remark 1:
	 The defining properties (Nl) to (N4) of a norm are suggested and motivated by the length |x| of a vector x in elementary vector algebra, so that in this case we can write ||x|| = |x|. It is not difficult to conclude from (Nl) to (N4) that (1) does define a metric. Hence normed spaces and Banach spaces are metric spaces.\\
	 we notice that (N4) implies *(2)* $\left| \|y\| - \|x\| \right| \leq \|y - x\|$ . Formula (2) implies an important property of the norm:
	 \[ \text{The norm is continuous, that is, $x \longmapsto \|x\|$ is a continuous mapping of $(X, \| \cdot \|)$ into $R$ .}\]
       - Remark 2:
	 /Can every metric on a vector space be obtained from a norm? The answer is no./
       - Lemma /(Translation invariance)/.
	 A metric d induced by a norm on a normed space X satisfies:\\
	 (a) $d(x+a, y+a)=d(x, y)$ \\
	 (b) $d(\alpha x, \alpha y) = |\alpha | d(x, y)$ \\
	 for all $x, y, a \in  X$ and every scalar $\alpha$ .
    3. Further Properties of Normed Spaces
       - Theorem /(Subspace of a Banach space)/.
	 A subspace Y of a Banach space X is complete if and only if the set Y is ciosed in X.\\
	 *Note: /By definition, a subspace Y of a Banach space X is a subspace of X considered as a normed space. Hence we do not require Y to be complete. (Some writers do, so be careful when comparing books.)/
       - Theorem (Completion 2). Let $X = (X, \|\cdot\|)$ be a normed space. Then there is a Banach space X' and an isometry A from X onto a subspace W of X' which is dense in X'. The space X' is unique, except for isometries.\\
	 *Note: The previous completion theorem /(completion 1)/ implies the existence of a complete metric space X' = (X', d') and an isometry A: X \to W = A(X), where W is dense in X' and X' is unique, except for isometries. Consequently, to prove the present theorem, we must make X' into a vector space and then introduce on X' a suitable norm.
    4. Finite Dimensional Normed Spaces and Suhspaces
       - Lemma /(Linear combinations)/.
	 Let $\{x_1,... ,x_n\}$ be a linearly independent set of vectors in a normed space X (/of any dimension/). Then there is a number c > 0 such that for every choice of scalars $\alpha_l, ... ,\alpha_n$ we have
	 \[ \|\alpha_1 x_1 + ... + \alpha_n x_n \| \geq c(|\alpha_1 | + ... + |\alpha_n |); (c > 0).\]
	 /Very roughly speaking it states that in the case of linear independence of vectors, we cannot find a linear combination that involves large scalars but represents a small vector./
       - Theorem /(Completeness)/.
	 Every finite dimensional subspace Y of a normed space X is complete. In particular, every finite dimensional normed space is complete.
       - Theorem /(Closedness)/.
	 Every finite dimensional subspace Y of a normel1 space X is closed in X.\\
	 *Remark:* \\
	 /Infinite dimensional subspaces need not be closed. For instance, consider the space of continuous functions X = C[0, 1] equipped with the maxnorm. Let Y be the subspace Y = span (1, t, t^2, ...) of polynomials. The exponential function is in $\overline{Y}$ but not in Y./
       - Definition /(Equivalent norms)/
	 /Another interesting property of a finite dimensional vector space X is that all norms on X lead to the same topology for X, that is, the open subsets of X are the same, regardless of the particular choice of a norm on X. The details are as follows:/ \\
	 A norm $\|\cdot\|$ on a vector space X is said to be equivalent to a norm $\|\cdot\|_0$ on X if there are positive numbers a and b such that for all $x \in X$ we have
	 \[  a\| x\|_0 \leq \| x \| \leq  b\| x\|_0 .\]
       - Theorem /(Equivalent norms)/.
	 On a finite dimensional vector space X, any norm $\|\cdot\|$ is equivalent to any other norm $\|x\|_0$.
    5. Compactness and Finite Dimension
       - Lemma /(Compactness)/.
	 A compact subset M of a metric space is closed and bounded. The converse of this lemma is in general false.
       - Theorem /(Compactness)/.
	 In a /finite dimensional normed space/ X, any subset M \subset X is compact if and only if M is closed and bounded.
       - Remark: /In R^n (or in any other finite dimensional normed space) the compact subse~ are precisely the closed and bounded subsets, so that this property (closedness and boundedness) can be used for defining compactness. However, this can no longer be done in the case of an infinite dimensional normed space./
       - Theorem (Finite dimension). If a normed space X has the property that the closed unit ball $M =\{x| \| x\| \leq 1\}$ is compact, then X is finite dimensional.
       - Theorem /(Continuous mapping)/.
	 Let X and Y be metric spaces and T: X \to Y continuous mapping. Then the image of a compact subset M of X under T is compact.
    6. 
    7. 
    8. Linear functional
       - The concept of "isomorphism," 
	 + In our work we are concerned with various spaces. Common to all of them is that they consist of a set, call it X, and a "structure" defined on X. For a metric space, this is the metric. For a vector space, the two algebraic operations form the structure. And for a normed space the structure consists of those two algebraic operations and the norm.
	 + By definition, this is a bijective mapping of X onto X' which preserves the structure.
	 + isomorphism T of a metric space is a bijective mapping which preserves distance.
	 + An isomorphism T of a vector space is a bijective mapping which preserves the two algebraic operations of vector space.
	 + Isomorphisms for normed spaces are vector space isomorphisms which also preserve norms
*** Chap 3 - Inner product spaces. Hilbert spaces
    1. 
*** Chap 4 - Fundamental theorems for Normed and Banach spaces
    1. *Zorn's Lemma*
       - /Zorn's lemma./\\
	 Let $M \neq \varnothing$ be a partially ordered set. Suppose that every chain $C \subset M$ has an upper bound. Then $M$ has at least one maximal element.\\
	 *Remark:
	 The name "lemma" is for historical reasons. Zorn's lemma can be derived from the /axiom of choice/, which states that for any given set $E$, there exists a mapping $c$ ("choice function") from the power set $P(E)$ into $E$ such that if $B \subset E, B \neq \varnothing$ , then $c(B) \in B$. Conversely, this axiom follows from Zorn's lemma, so that /Zorn's lemma and the axiom of choice can be regarded as equivalent axioms./
       - Hamel basis (lemma).
	 Every vector space X \neq {0} has a /Hamel basis/ (the basis which spans X).
       - 
    2. *Adjoint Operator*
       - Compare $T^\times$ vs $T^*$:\\
	 Differences between the /adjoint/ operator $T^\times$ of $T: X \to Y$ and the /Hilbert-adjoint/ operator $T^*$ of $T: H_1 \to  H_2$, where X, Y are normed spaces and H_1, H_2 are Hilbert spaces
	 + $T^\times$ is defined on the dual of the space which contains the range of T, whereas $T^*$ is defined directly on the space which contains the range of T.
	 + For $T^\times$ : $(\alpha T)^\times = \alpha T^\times$ ; for $T^*$ : $(\alpha T)^* = \overline{\alpha} T^*$.
	 + In the finite dimensional case, $T^\times$ is represented by the transpose of the matrix representing T, whereas $T^*$ is represented by the complex conjugate transpose of that matrix.
    3. Reflexive spaces
    4. *Category Theorem. Uniform Boundedness Theorem*
       - Definition (Category).\\
	 A subset M of a metric space X is said to be\\
	 (a) /rare/ (or nowhere dense) in X if its closure $\overline{M}$ has no interior points\\
	 (b) /meager/ (or of the first category) in X if M is the union of countably many sets each of which is rare in X,\\
	 (c) nonmeager (or of the second category) in X if M is not meager in X.\\
	 Each concept has two names, a new name and an old one given in parentheses.
       - *Baire's Category Theorem* /(Complete metric spaces)/. \\
	 If a metric space $X \neq \varnothing$ is complete, it is nonmeager in itself.\\
	 Hence if $X \neq \varnothing$ is complete and
	 \[ X = \bigcup_{k=1}^\infty A_k \text{ ( $A_k$ closed)}\]
	 then at least one $A_k$ contains a nonempty open subset.
       - *Uniform Boundedness Theorem.* \\
	 Let $(T_n)$ be a sequence of bounded linear operators $T_n: X \to Y$ from a Banach space $X$ into a normed space $Y$ such that $(\|T_n x\|)$ is bounded for every $x \in X$, say,
	 \[ \|T_n x\| \leq c_x; n=1,2,... \]
	 where c_x is a real number. Then the sequence of the norms ||T_n|| is bounded, that is, there is a c such that
	 \[ \|T_n\| \leq c;  n=1,2,... \]
    5. *Strong and Weak Convergence*
       - Definition /(Strong convergence)/. \\
	 A sequence $(x_n)$ in a normed space $X$ is said to be strongly convergent (or convergent in the norm) if there is an $x \in X$ such that
	 \[\lim_{n\to\infty}\|x_n - x\| = 0. \]
	 This is written
	 \[ \lim_{n\to\infty}x_n= x\]
	 or simply
	 \[ x_n \longrightarrow x. \]
	 $x$ is called the strong limit of $(x_n)$, and we say that $(x_n)$ converges strongly to $x$.
       - Definition /(Weak convergence)/. \\
	 A sequence $(x_n)$ in a normed space $X$ is said to be weakly convergent if there is an $x \in X$ such that for every $f \in X'$,
	 \[\lim_{n\to\infty} f(x_n) = f(x).\]
	 This is written
	 \[ x_n \xrightarrow{\quad w \quad} x \]
	 or $x_n \rightharpoonup x$. The element $x$ is called the weak limit of $(x_n)$, and we say that $(x_n)$ converges weakly to $x$.
    6. Convergence of Sequences of Operators and Functionals
       - Definition /(Convergence of sequences of operators)/.\\
	 Let $X$ and $Y$ be normed spaces. A sequence $(T_n)$ of operators $T_n \in B(X, Y)$ is said to be:\\
	 (1) /uniformly operator convergent/ if $(T_n)$ converges in the norm on $B(X, Y)$ \\
	 (2) /strongly operator convergent/ if $(T_n x)$ converges strongly in $Y$ for every $x \in X$,\\
	 (3) /weakly operator convergent/ if $(T_n x)$ converges weakly in $Y$ for every $x \in X$.
       - Definition /(Strong and weak* convergence of a sequence of functionals)/.\\
	 Let $(f_n)$ be a sequence of bounded linear functionals on a normed space $X$. Then:\\
	 (a) /Strong convergence/ of $(f_n)$ means that there is an $f \in X'$ such that $\|f_n - f\| \rightarrow 0$. This is written $f_n \rightarrow f$. \\
	 (b) /Weak* convergence/ of $(f_n)$ means that there is an $f \in X'$ such that $f_n(x) \rightarrow f(x)$ for all $x \in X$. This is written $f_n \xrightarrow{\quad w* \quad} f$.\\
	 $f$ in (a) and (b) is called the /strong limit and weak* limit/ of $(f_n)$, respectively.
       - *Remark:* If the convergence is uniform, $T \in B(X, Y)$ ; otherwise $\|T_n - T\|$ would not make sense. If the convergence is strong or weak, $T$ is still linear but may be unbounded if $X$ is not complete.
    7. *Open mapping theorem*
       - Definition /(Open mapping)/. \\
	 Let X and Y be metric spaces. Then T: D(T) \to Y with domain D(T) \subset X is called an open mapping if for every open set in D(T) the image is an open set in Y. \\
	 *Note*: Note that if a mapping is not surjective, one must take care to distinguish between the assertions that the mapping is open as a mapping from its domain \\
	 (a) into Y,\\
	 (b) onto its range.\\
	 (b) is weaker than (a). For instance, if X \subset Y, the mapping x \mapsto x of X into Y is open if and only if X is an open subset of Y, whereas the mapping x \mapsto x of X onto its range (which is X) is open in any case.
    8. *Closed Linear Operators. Closed Graph Theorem*
       - Definition /(Closed Hnear operator)/.\\
	 Let $X$ and $Y$ be normed spaces and $T: D(T) \longmapsto Y$ a linear operator with domain $D(T) \subset X$. Then T is called a /closed linear operator/ if its graph
	 \[G(T)=\{(x,y) | x\in D(T), y=Tx\}\]
	 is closed in the normed space $X \times Y$, where the two algebraic operations of a vector space in $X \times Y$ are defined as usual, that is
	 \[(x_1,y_1) + (x_2,y_2) = (x_1 + X_2, y_1 + y_2)\]
	 \[ \alpha (x, y) = (\alpha x, \alpha y)\]
	 ($\alpha$ a scalar) and the norm on $X \times Y$ is defined by
	 \[ \|(x, y)\| =\|x\| + \|y\|. \]
*** Chap 7 - SPECTRAL THEORY OF LINEAR OPERATORS IN NORMED SPACES
    1. *Spectral Theory in Finite Dimensional Normed Spaces*
       - *Definition /(spectrum, resolvent set of a matrix)/* \\
	 The set $\sigma (A)$ of all eigenvalues of matrix $A$ is called the /spectrum/ of $A$. Its complement $\rho (A) = C - \sigma (A)$ in the complex plane is called the /resolvent set/ of $A$.
       - *Note*: if \xi \in \rho (A) then A - \xi I is invertible
    2. *Basic concepts*
       - *Definition /(Regular value, resolvent set, spectrum)/.* \\
	 Let $X \neq {O}$ be a complex normed space and $T: D(T) \to X$ a linear operator with domain D(T) \subset X$. A regular value $\lambda$ of $T$ is a complex number such that\\
	 $\quad$ (Rl) $R_\lambda (T)$ exists,\\
	 $\quad$ (R2) $R_\lambda (T)$ is bounded,\\
	 $\quad$ (R3) $R_\lambda (T)$ is defined on a set which is dense in $X$.\\
	 The /resolvent set/ $\rho (T)$ of $T$ is the set of all regular values $\lambda$ of $T$. Its complement $\sigma (T) = C - \rho (T)$ in the complex plane $C$ is called the /spectrum/ of $T$, and a $\lambda \in \sigma (T)$ is called a /spectral value/ of $T$. Furthermore, the spectrum $\sigma (T)$ is partitioned into three disjoint sets as follows.\\
	 $\quad$ The *point spectrum* or *discrete spectrum* $\sigma_p (T)$ is the set such that $R_\lambda (T)$ does not exist. A $\lambda \in \sigma_p (T)$ is called an /eigenvalue/ of $T$.\\
	 $\quad$ The *continuous spectrum* $\sigma_c (T)$ is the set such that $R_\lambda (T)$ exists and satisfies (R3) but not (R2), that is, $R_\lambda (T)$ is unbounded.\\
	 $\quad$ The *residual spectrum* $\sigma_r (T)$ is the set such that $R_\lambda (T)$ exists (and may be bounded or not) but does not satisfy (R3), that is, the domain of $R_\lambda (T)$ is not dense in $X$.
*** Chap 8 - Compact linear operators on normed spaces and their spectrum
    1. *Compact Linear Operators on Normed Spaces*
       - *Definition /(Compact linear operator)/*. \\
	 Let $X$ and $Y$ be normed spaces. An operator $T: X \to Y$ is called a /compact linear operator/ (or /completely continuous linear operator/) if $T$ is linear and if for every bounded subset $M$ of $X$, the image $T(M)$ is /relatively compact/, that is, the closure $\overline{T(M)}$ is compact.
** Functional analysis - Gustav Holzegel's note
*** Normed Spaces and Banach Spaces
    1. Definition /(linearly independent)/.\\
	 A set $M \subset X$ is called linearly independent if */every finite subset/* of $M$ is linearly independent.
    2. Definition /(Hamel basis)/. \\
	 A set $E \subset X$ is called a Hamel basis of $X$ if $E$ is linearly independent and every vector $x \in X$ can be written uniquely as a finite linear combination of elements in $E$.
    3. Definition /(Schauder basis)/.\\
	 If a normed space X contains a sequence $e_n$ with the property that for every $x \in X$ there is a unique sequence of scalars $\alpha_n$ such that $\| x − \alpha_1 e_1 − \alpha_2 e_2 − ... \alpha_n e_n \| \to 0$ as $n \to \infty$ then $(e_n)$ is called a /Schauder basis/ of $X$.
    4. Lema: if X has a Schauder basis, then it is separable. (The converse is in general false.)
*** Linear Operators
    1. Lema: The operator norm is indeed a norm.
    2. Theorem: If a normed space is finite dimensional then every linear operator T on X is bounded.
    3. Theorem: \\
       Let $T: D(T) \to Y$ be a linear operator where $D(T) \subset X$ and $X; Y$ are normed spaces. Then \\
       (1) $T$ is continuous /if and only if/ $T$ is bounded\\
       (2) If $T$ is continuous at a single point it is continuous everywhere
    4. Note: the space of all linear functionals on a vector space can itself be made into a vector space. This vector space is denoted $X^*$ and called the /algebraic dual space/ of $X$. The linear operations are defined as expected:
       \[(f_1 + f_2)(x) = f_1(x) + f_2(x); (\alpha f)(x) = \alpha f(x).\]
       The algebraic dual space is to be distinguished from the /dual space/, which is _the space of /bounded (=continuous)/ linear functionals_ in the context of normed spaces.
    5. *Theorem*:\\
       Let X; Y be normed spaces. If Y is a Banach space, then B(X,Y) is a Banach space.\\
       */Note/*: /An important consequence of this theorem is that if you consider bounded linear functionals from a normed space X into R or C (which are complete), then independently of whether the domain is complete or not, the space of bounded linear functionals will be complete./
*** The dual space and the Hahn-Banach theorem
    1. *Definition /(affine hyperplane)/* \\
       The zero set of a linear functional $f(v) = 0$ represents a /hyperplane/ in $R^n$ and, more generally, the set $\{v | f(v) = c\}$ represents a translated (affine) hyperplane. We adapt these definitions for an arbitrary (possibly $\infty$ -dimensional) vector space $V$ over $R$, i.e. we call the set $H = \{v \in V | f(v) = c\}$ an /affine hyperplane/ in $V$.
    2. *Definition /(Convex set)/*
	A set $K \subset V$ is /convex/ if $v_0, v_1 \in K$ implies that
	\[ v(t) = (1 − t)v_0 + tv_1 \]
	lies in $K$ for all $0 \leq t \leq 1$.
    3. *Theorem /(Hahn-Banach)/*\\
       Let $V$ be a real vector space and $p$ a sublinear functional on $V$ . Let $M \subset V$ be a linear subspace and $f$ a linear functional on $M$ satisfying
       \[ f(v) \leq p(v) \text{ for all } v \in M.\]
       Then $f$ can be extended on all of $V$ such that
       \[ F(v) \leq p(v) \text{ for all } v \in V \quad \text{ and } \quad F(v) = f(v) \text{ for } v \in M.\]
       *Note: if the context is clear, the terms linear subspace and subspace can be used interchangeably.
*** Some Spectral Theory: Compact Operators
    1. Infinite diagonal matrices
       - Operator $T: H \to H$ called a linear transformation diagonalized if with respect to some /orthonormal basi/s $(\varphi )_{k=1}^\infty$ we have for all $k$
	 \[ T\varphi_k = \lambda_k\varphi_k \text{ with } \lambda_k \in C\]
	 In other words the $\{\lambda_k\}$ are eigenvectors with eigenvalue $\lambda_k$. Therefore, if we have
	 \[ f = \sum_{k=1}^\infty \alpha_k\varphi_k \text{ then } Tf = \sum_{k=1}^\infty \alpha_k\lambda_k\varphi_k.\]
	 The sequence $\{\lambda_k\}$ is called the /multiplier sequence/ corresponding to $T$.
    2. Theorem:\\
       Suppose $T$ is a /compact self-adjoint operator/ $T : H \to H$ for $H$ a(separable) infinite dimensional Hilbert space. Then there exists an orthonormal basis $\{\varphi_k\}){k=1}^\infty$ of $H$ consisting of eigenvectors of $T$:
       \[ T\varphi_k = \lambda_k\varphi_k.\]
       Moreover, $\lambda_k \in R$ and $\lambda_k \to 0$ as $k \to \infty$.
       *Note: /In the case of finite dimensional Hilbert spaces, the theorem reduces to the familiar theorem in linear algebra about diagonalizing symmetric matrices./
* Some confusing things:
** Some terms about function or mapping or operator (vector spaces)
   1. Let $D(T) \subset X$ and $R(T) \subset Y$, where $X$ and $Y$ are vector spaces, both real or both complex. Then $T$ is an operator from (or mapping of) $D(T)$ *onto* $R(T)$, written
      \[ T: D(T) \to R(T)\]
      or from $D(T)$ *into* $Y$, written
      \[ T: D(T) \to  Y.\]
      If $D(T)$ is the whole space $X$, /then-and only then/- we write
      \[ T: X \to Y.\]
   2. D(T): Domain of T
   3. R(T): Range of T, some time called Imange of T (some text use for retriction of T on subset of domain)
   4. Y: Codomain of T
   5. Preimage: of subset of the codomain is the set of all inputs that produce outputs in that set.
   6. Injection: two - to - two function. Giữ nguyên tính phân biệt và đầy đủ của các phần tử trong domain (giống hình ảnh ống tiêm - tiêm vào codomain)
   7. Surjection: every elements in codomain have at least a coresponding element in domain that map to it.
   8. Bijection: Injection + Surjection
   9. Inverse of function: a function have an inverse iff it is bijective.
   10. Preimage and inverse notation: $f^{-1}(B)$ vs $f^{-1}(x)$. B is a subset of codomain of f. x is an element of domain of f.
   11. In some texts, defintion of function might be different and confusing with relation. they may use terms like total, well-define, partial function....
** Interchange of limits
   1. Continuity of the limit: $f_n$  be a sequence of continuous functions /uniformly convergence/ to $f$ \\
      - Continuity of limits = limit of continuities\\
      - $\lim_{k\to\infty}(\lim_{n\to\infty}f_n(x_k) = \lim_{n\to\infty}(\lim_{k\to\infty}(f_n(x_k))$
      - $\lim_{k\to\infty} f(x_k) = \lim_{n\to\infty}f_n(x)$
   2. Integral of limits: $f_n$  be a sequence of Riemann integrable functions /uniformly convergence/ to $f$ \\
      - Integral of limits = limit of integrals\\
      - $\int_a^b \lim_{n\to\infty} f_n = \lim_{n\to\infty}\int_a^b f_n$
      - $\int_a^b f = \lim_{n\to\infty}\int_a^b f_n$
   3. Derivative of limits: if $f'_n$ /converges uniformly/ to $f'$, and $f_n(x_0)$ converges for some $x_0$, then $f_n$ also /converges uniformly/ to $f$ (on bounded interval), and:\\
      - Derivative of limits = limit of derivarives
      - $f'(x) = \frac{d}{dx} \lim_{n\to\infty} f_n(x) = \lim_{n\to\infty}\frac{d}{dx}f_n(x) =  \lim_{n\to\infty} f'_n(x)$
** Interchange (swap) integrals or infite sums (several variables)
   1. ex: see Tenren Tao's analysis
** Interchanging limits or derivatives (several variables)
   1. ex: see Tenren Tao's analysis
* Calculus
** Multivarible calculus
*** 
* Algebra
** Resources
*** chicago-ug-math-bib
**** Intermediate - Abstract algebra
     1. Dummit/Foote, Abstract algebra: Comprehensive, very good for reference.
     2. Herstein, Topics in algebra
     3. Artin, Algebra: nontraditional approach to undergraduate algebra, emphasizing concrete computational examples heavily throughout. used in MIT OCW courses.
     4. Hungerford, Algebra: might be good, some dont like it
     5. a book of abstract algebra: charles Pinter. might be very good.
     6. Fraleigh J.B. A First Course in Abstract Algebra - Fraleigh made it, he gives a good introduction abstract algebra for newbie. Ideal for a first coures.
     7. Jacobson N. Basic Algebra I
** A book of abstract algbera - Charles C.Pinter
*** Groups
    1. *Definition:* \\
       By a group we mean a set $G$ with an operation $*$ which satisfies the axioms:\\
       (Gl) $*$ is associative.\\
       (G2) There is an element $e \in G$ such that $a * e = a$ and $e * a = a$ for every element $a \in G$.\\
       (G3) For every element $a \in G$, there is an element $a^{-1} \in G$ such that $a * a^{-1} = e and $a^{-1} * a = e$.\\
       *Note: If the commutative law holds in a group $G$, such a group is called a /commutative group/ or, more commonly, an /abelian group/.
    2. *Order of G*: \\
       If G is a finite group, the number of elements in G is called the order of G. It is customary to denote the order of G by the symbol |G|.
    3. *Definition /(subgroup)/*: /(informal, my own words)./ 
       - We call S a subgroup of G if S is /closed with respect to operation/ of G and is /closed with respect to inverses/ of that operation.
       - Lema: /if G is a group and S is a subgroup of G, then S itself is a group/
    4. *Definition /(cyclic subgroup of G)/*: /Informal/
       - If a_1 ,... , a_n are any finite number of elements of G, we define S to be the subgroup of G /generated by/ a_1 ,... , a_n  which contains all the possible products or sum of a_1,... , a_n and their inverses. /(in other words, in any group G, a set S of elements of G is said to generate G if every element of G can be expressed as a product of elements in S and inverses of elements in S.)/
       - In particular, if a is a single element of G, we may consider the subgroup generated by a. This subgroup is designated by the symbol <a>, and is called a /cyclic subgroup/ of G; a is called its generator.
    5. *Definition /(semigroup)/:
       - A set A with an associative operation is called a /semigroup/. (There does not need to be an identity element, nor do elements necessarily have inverses.) 
*** Groups of permutations
    1. *Definition/(Permutation)/:*
       - By a permutation of a set A we mean a bijective function from A to A, that is, a one-to-one correspondence between A and itself.
    2. *Definition /(identity function)/:*
       - For any set A , the identity function on A; symbolized by $\epsilon_A$ or simply $\epsilon$, is the function x \to x which carries every element of A to itself. That is, it is defined by
	 \[ \epsilon(x) = x \text{ for every element } x \in A \]
       - Lema: /the set of all the permutations of A, with the operation $\circ$ of composition, is a group/
    3. *Definition /(Symetric group on A)/*:
       - For any set A , the /group of all the permutations/ of A is called the /symmetric group/ on A, and it is represented by the symbol S_A . For any positive integer n, the symmetric group on the set {l, 2, 3,... , n} is called the /symmetric group on n elements/, and is denoted by S_n.
       - *Remark:* By a /group of permutations/ we mean any group S_A or S_n , or any subgroup of one of these groups. Among the most interesting groups of permutations are the groups of symmetries of geometric figures /(just a subgroup of S_A with A is set of all vertices of the figure - my own words)/.
       - For every positive integer n \geq 3, the regular polygon with n sides has a group of symmetries, symbolized by D_n, which may be found as we did here. These groups are called the /dihedral groups/. For example, the group of the square is D_4, the group of the pentagon is D_5, and so on.
*** Permutations of a finite set
    1. *Definition /(cycle)/:*
       - Let a_1 , a_2 ,... , as be distinct elements of the set {1, 2, . . . , n} . By the cycle (a_1 a_2 ...  a_s ) we mean the permutation a_1 \to a_2 \to ... \to a_s \to a_1 ... of {1, 2, . . . , n}, while leaving all the remaining elements of {1, 2, . . . , n} fixed.
       - If (a_1 a_ 2 ... a_s ) is a cycle, the integer s is called  its length; thus, (a_1 a_2 ...  a_s ) is a cycle of length s. A cycle of length 2 is called a /transposition/.
       - Lema: If two cycles have no elements in common they are said to be /disjoint/. Disjoint cycles commute.
    2. *Theorem 1*:
       - /Every permutation is either the identity, a single cycle, or a product of disjoint cycles./
       - *Remark*: \\
	 Every permutation, after it has been decomposed into disjoint cycles, may be brokern down further and expressed as a /product of transpositions/. However, the expression as a product of transpositions is not unique, and even the number of transpositions involved is not unique. Nevertheless, when a permutation \pi is written as a product of transpositions, one  property of this expression is unique: /the number of transpositions involved is either always even or always odd./
    3. *Theorem 2*:
       - No matter how \epsilon written as a product of transpositions, the number of transpositions is even.
    4. *Theorem 3*:
       - /If \pi \in S_n, then \pi cannot be both an odd permutation and an even permutation./
       - Note: The set of all the even permutations in S_n is a subgroup of S_n. It is denoted by A_n, and is called the /alternating group/ on the set {1, 2,... , n}.
    5. *Definition /(Conjugate Cycles)/:*
       - Let \alpha = (a_1,... , a_s ) be a cycle and let \pi be a permutation in S_n. Then $\pi \alpha \pi^{-1}$ is the cycle $(\pi(a_1) ,... , \pi(a_s))$ .If \alpha is any cycle and \pi any permutation, $\pi \alpha \pi^{-1}$ is called a /conjugate of \alpha/.
       - Lema: /Any two cycles of the same length are conjugates of each other./
    6. *Definition /(order of an permutation)/:*
       - If \alpha is any permutation, the least positive integer n such that \alpha^n = \epsilon is called the order of \alpha .
*** Isomorphism
    1. *Definition:*
       - Let G_1 and G_2 be groups. A bijective function f: G_1 \to G_2 with the property that for any two elements a and b in G_1 ,
	 \[ f(ab) = f(a)f(b) \]
	 is called an /isomorphism/ from G_1 to G_2 . If there exists an isomorphism from G_1 to G_2 , we say that G_1 is /isomorphic/ to G_2 .
	 \[ \text{we write } G_1 \cong G_2 \]
    2. *Cayley's Theorem*:
       - Every group is isomorphic to a group of permutations.
*** Order of group elements
    1. *Definition /(order of group elements)/*:
       - If there exists a nonzero integer m such that a^m = e, then the order of the element a is defined to be the least positive integer n such that a^n = e. If there does not exist any nonzero integer m such that a^m = e, we say that a has order infinity.
       - If a is any element of a group, we will denote the order of a by *ord(a)*
*** Counting cosets
    1. *Definition /(Coset)/:*
       - Let G be a group, and H a subgroup of G. For any element a in G, the symbol aH denotes the set of all products ah, as a remains fixed and h ranges over H. aH is called a left coset of H in G.
       - In similar fashion, Ha denotes the set of all products ha, as a remains fixed and h ranges over H. Ha is called a right coset of H in G.
       - note: /In practice, it will make no difference whether we use left cosets or right cosets, just as long as we remain consistent. Thus, from here on, whenever we use cosets we will use right cosets. To simplify our sentences, we will say coset when we mean "right coset."/
    2. *Theorem 1*:
       - The family of all the cosets Ha, as a ranges over G, is a partition of G.
    3. *Theorem 2:*
       - If Ha is any coset of H, there is a one-to-one correspondence from H to Ha.
    4. *Lagrange's theorem:*
       - Let G be a finite group, and H any subgroup of G. The order of G is a multiple of the order of H.
    5. *Theorem 4:*
       - If G is a group with a prime number p of elements, then G is a cyclic group. Furthermore, any element a \neq e in G is a generator of G.
    6. *Theorem 5:*
       - The order of any element of a finite group divides the order of the group.
       - if G is a group and H is a subgroup of G, /the index/ of H in G is the number of cosets of H in G. We denote it by (G:H)
	 \[ (G:H) =  \dfrac{\text{order of } G}{\text{order of } H}\]
    7. *Cauchy's theorem:*
       - If G is a finite group, and p is a prime divisor of |G|, then G has an element of order p.
*** Homomorphisms
    1. *Definition /(Homomorphism)/:*
       - If G and H are groups, a *homomorphism* from G *to* H is a function f: G \to H such that for any two elements a and b in G, f(ab) = f(a)f(b)
       - If there exists a homomorphism from G *onto* H, we say that H is a *homomorphic image* of G.
       - /The underlying idea is:/ In a homomorphic image of G, some aspect of G is isolated and faithfully preserved while all else is deliberately lost.
    2. *Theorem 1*:
       - Let G and H be groups, and f: G \to  H a homomorphism. Then; \\
	 (i) f(e) = e, and \\
	 (ii) $f(a^{-1}) = [f(a)]^{-1}$ for every element a \in G
    3. *Definition /(normal subgroup)/*:
       - Let H be a subgroup of a group G. H is called a normal subgroup of G if it is closed with respect to conjugates, that is, if
	 \[\text{for any } a \in H \text{ and } x \in G \quad xax^{-1} \in H \]
       - Note that according to this definition, a normal subgroup of G is any nonempty subset of G which is closed with 'respect to products, with respect to inverses, and with respect to conjugates.
    4. *Definition /(kernel)/:*
       - Let f: G \to H be a homomorphism. The *kernel* of f is the set K of all the elements of G which are carried by f onto the neutral element of H. That is,
	 \[ K = \{x \in G: f(x) = e\} \]
    5. *Theorem:*
       - Let f: G \to H be a homomorphism.\\
	 (i) The kernel of f is a normal subgroup of G, and\\
	 (ii) The range of f is a subgroup of H.
*** Quotient groups
    1. *Theorem 1 /(property of normal subgroup)/:*
       - If H is a normal subgroup of G, then aH = Ha for every a \in G.
       - In other words, there is no distinction between left and right cosets for a normal subgroup.
    2. *Theorem 2*
       - Let H be a normal subgroup of G. If Ha = Hc and Hb = Hd, then H(ab) = H(cd).
    3. *Quotient Group*:
       - Let G be a group and let H be a /normal subgroup/ of G. The set which consists of all the cosets of H is denoted by G/H. Thus, if Ha, Hb, He, . . . are cosets of H, then G/H = {Ha, Hb, He, . . . }
       - *Theorem 3*: G/H with coset multiplication - Ha.Hb = H(ab) - is a group. /Note: For coset multiplication uniquely defined, H need to be normal subgroup/
       - The group G/H is called the /factor group/, or /quotient group/ of G by H.
    4. *Theorem 4*:
       - G/H is a homomorphic image of G.
    5. *Theorem 5*
       - Let G be a group and H a subgroup of G. Then\\
	 (i) $Ha = Hb$ iff $ab^{-1} \in H$ and \\
	 (ii) $Ha = H$ iff $a \in H$
*** The fundamental homorphism theorem
    1. *Theorem 1*:
       - Let f: G \to H be a homomorphism with kernel K. Then f(a) = f(b) iff Ka = Kb
       - In other words, any two elements a and b in G have the same image under f iff they are in the same coset of K.
    2. *Theorem 2 /(fundamental homomorphism theorem)/:*
       - Let f: G \to H be a homomorphism of G onto H. If K is the kernel of f, then $H \cong G/K$.
*** Rings: Definitions and elementary properties
    1. *Theorem 1:*
       - Let a and b be any elements of a ring A.\\
	 (i) a0 = 0 and 0a = 0 \\
	 (ii) a(-b) = -(ab) and (-a)b = -(ab) \\
	 (iii) (-a)(-b) = ab
    2. Note 1:
       - In any ring, a nonzero element a is called a *divisor of zero* if there is a nonzero element b in the ring such that the product ab or ba is equal to zero. For example, in Z_6, 2.3 = 0.
    3. Note 2:
       - A ring is said to have the *cancellation property* if ab = ac or ba = ca implies b = c for any elements a, b, and c in the ring if a \neq 0
    4. *Theorem 2:*
       - A ring has the cancellation property iff it has no divisors of zero.
*** Ideals and Homomorphisms
    1. *Subring:*
       - If a nonempty subset B \subseteq A is closed with respect to addition, multiplication, and negatives, then B with the operations of A is a ring.
       - /B is a subring of A if and only if B is closed with respect to subtraction and multiplication. The reason is that B is closed with respect to subtraction iff B is closed with respect to both addition and negatives./
    2. *Ideals:*
       - A nonempty subset B of a ring A is called an ideal of A if B is closed with respect to addition and negatives, and B absorbs products in A /(for all b \in B and x \in A, xb and bx are in B.)/.
    3. *Homomorphisms:*
       - A homomorphism from a ring A to a ring B is a function f : A \to B satisfying the identities
	 \[f(x_1 + X_2) = f(x_1) + f(x_2)\]
	 and
	 \[ f(x_1x_2) = f(x_1)f(x_2)\]
    4. *Kernel:*:
       - If f is a homomorphism from a ring A to a ring B, the *kernel of f* is the set of all the elements of A which are carried by f onto the zero element of B. In symbols, the kernel of f is the set K = {x \in A : f(x) = 0}
       - /It is a very important fact that the kernel of f is an ideal of A./
*** Quotient rings
    1. *Cosets of rings:*
       - Let A be a ring, and J an ideal of A. For any element a \in A, the symbol J + a denotes the set of all sums j + a, as a remains fixed and j ranges over J. That is,
	 \[ J + a = \{j + a : j \in J\}\]
	 J + a is called a *coset* of J in A
    2. *Theorem 1*
       - Let J be an ideal of A. If J + a = J + c and J + b = J + d, then\\
	(i) J + (a + b) = J + (c + d) , and \\
	(ii) J + ab = J + cd.
    3. *Theorem 2:* A/J with coset addition and multiplication is a ring (quotient ring).
    4. *Theorem 3:* A/J is a homomorphic image of A.
    5. *Theorem 4:* Let f : A \to B be a homomorphism from a ring A onto a ring B, and let K be the kernel of f. Then B \cong A/K.
    6. Note:
       - Theorems 3 and 4 together assert that every quotient ring of A is a homomorphic image of A, and, conversely, every homomorphic image of A is isomorphic to a quotient ring of A. Thus, for all practical purposes, quotients and homomorphic images of a ring are the same.
       - As in the case of groups, there are many practical instances in which it is possible to select an ideal J of A so as to "factor out" unwanted traits of A, and obtain a quotient ring A/J with "desirable" features.
*** Intergral domains
    1. Definition /(integral domain)/:*
       - An integral domain is a commutative ring with unity having the cancellation property, that is, if a \neq 0 and ab = ac then b = c.
       - The term "integral domain" means a system of algebra ("domain") having integerlike properties.
    2. *Definition /(Characteristic of ring with unity)/:*
       - In a ring with unity, if 1 has additive order n, we say the ring has "characteristic n." In other words, if A is a ring with unity, the *characteristic* of A is the least positive integer n such that
	 \[ (1 + 1 + · · · + 1)_{n\_times} = 0 \]
	 If there is no such positive integer n, A has *characteristic 0*.
    3. *Theorem 1*: All the nonzero elements in an integral domain have the same additive order.
    4. *Theorem 2:/
       - In an integral domain with nonzero characteristic, the characteristic is a prime number.
       - PROOF: If the characteristic were a composite number mn, then by the distributive law,
	 \[ (m.1)(n.1) = (1 + · · · + 1)_{m\_terms} (1 + · · · + 1)_{n\_terms} = (1 + 1 + · · · + 1)_{mn\_terms} = (mn).1 = 0 \]
	 Thus, either m.1 = 0 or n.1 = 0, which is impossible because mn was chosen to be the least positive integer such that (mn).1 = 0.
    5. *Theorem 3:*
       - In any integral domain of characteristic p, for all elements a and b
	 \[ (a + b)^p = a^p + b^P \]
       - PROOF: This formula becomes clear when we look at the binomial expansion. /Note that the binomial formula is correct in every commutative ring/.
    6. *Theorem 4*: Every *finite* integral domain is a field.
*** The integers
    1. *Integral system:*
       - The set of all the positive elements of A is denoted by $A^+$
       - An ordered integral domain A is called an integral system if every nonempty subset of $A^+$ has a least element. In other words, /if every nonempty set of positive elements of A has a least element/. This property is called the /well-ordering property/ for $A^+$.
    2. *Theorem: every integral system is isomorphic to Z.
*** Factoring into primes
    1. *Theorem 1*: Every ideal of Z is principal.
    2. *Principal ideal*:
       - In a commutative ring with unity, the set of all the multiples of a fixed element a by all the elements in the ring - in other words, the set of all the products /xa/ as /a/ remains fixed and /x/ ranges over all the elements of the ring - is called the *principal ideal generated by a*, and is denoted by /<a>/
*** Rings of Polynomials
    1. *Theorem 1:* Let A be a commutative ring with unity. Then A[x] is a commutative ring with unity.
    2. *Theorem 2:*
       - If A is an integral domain, then A[x] is an integral domain.
       - If A is an integral domain, we refer to A[x] as a /domain of polynomials/
    3. *Theorem 3 /(Division algorithm for polynomials)/:*
       - If a(x) and b(x) are polynomials over a field F, and b(x) \neq 0, there exist polynomials q(x) and r(x) over F such that \\
	 a(x) = b(x)q(x) + r(x) \\
	 and r(x) = 0 or deg r(x) < deg b(x)
*** Factoring Polynomials
    1. *Theorem l:*
       - Every ideal of F[x] is principal.
       - Note carefully that in F[x], the principal ideal generated by a polynomial a(x) consists of all the products a(x)s(x) as a(x) remains fixed and s(x) ranges over all the members of F[x].
    2. *Theorem 2:*
       - Any two nonzero polynomials a(x) and b(x) in F[x] have a gcd d(x). Furthermore, d(x) can be expressed as a "linear combination"
	 \[d(x) = r(x)a(x) + s(x)b(x)\]
	 where r(x) and s(x) are in F[x].
    3. *Definition:*
       - *Relatively prime*: Polynomials a(x) and b(x) in F[x] are said to be relatively prime if their gcd is equal to 1 . (This is equivalent to saying that their only common factors are constants in F.)
       - *Reducible*: A polynomial a(x) of positive degree is said to be *reducible over* F if there are polynomials b(x) and c(x) in F[x], both of positive degree, such that a(x) = b(x)c(x).
       - *Irreducible:* A polynomial p(x) of positive degree in F[x] is said to be *irreducible over* F if it cannot be expressed as the product of two polynomials of positive degree in F[x]. Thus, p(x) is irreducible iff it is not reducible. /Note: When we say that a polynomial p(x) is irreducible, it is important that we specify irreducible over the field F. A polynomial may be irreducible over F, yet reducible over a larger field E. For example, p(x) = x^2 + 1 is irreducible over R; but over C it has factors (x + i)(x - i)./
    4. *Theorem 3 /(Factorization into irreducible polynomials)/
       - Every polynomial a(x) of positive degree in F[x] can be written as a product
	 \[ a(x) = kp_1(x)p_2(x)...p_r(x) \]
	 where k is a constant in F and $p_1(x),... , p_r(x)$ are /monic irreducible polynomials/ of F[x].
    5. *Theorem 4 /(Unique factorization)/:*
       - If a(x) can be written in two ways as a /product of monic irreducibles/, say
	 \[ a(x) = kp_1(x)...p_r(x) = lq_1(x)... q_s(x) \]
	 then k = l, r = s, and each $p_i(x)$ is equal to a $q_j(x)$ .
*** Extension of fields
    1. 
*** Notation
    1. $\overline{a}$ : If a is any integer, the coset (in $Z_n$)  which contains a will be denoted by $\overline{a}$
    2. A[x]: the set of all polynomials whose coefficients are in ring A.
    3. F[x]: the set of all polynomials whose coefficients are in filed F.
** A first course in abstract algebera - Fraleigh
   1. *Group and Subgroup:*
      - *Group:* Has 3 properties: associativity + identity element + inverse
      - *Theorem:* /Every cyclic group is abelian/
      - *Theorem:* Let G be a cyclic group with generator a. If the order of G is infinite, then G is isomorphic to <Z,+> If G has finite order n, then G is isomorphic to <Z_n ,+>
      - *Theorem:* Let $\varphi : G \to G'$ be a group homomorphism. Then the left and right cosets of $Ker(\varphi)$ are identical. Furthermore, $a, b \in G$ are in the same coset of $Ker(\varphi)$ if and only if $\varphi (a) = \varphi (b)$
      - *Theorem:* The following are four equivalent conditions for a subgroup H of a group G to be a normal subgroup of G.\\
	1) ghg^−1 \in H for all g \in G and h \in H.\\
	2) gHg^−1 = H for all g \in G. \\
	3) There is a group homomorphism φ : G \to G' such that Ker(φ) = H. \\
	4) gH = Hg for all g \in G.
      - *Definition /(Alternating group A_n)/*: The subgroup of S_n consisting of the even permutations of n letters is the *alternating group* A_n  on n letters.
      - *Remark: /(The Converse of the Theorem of Lagrange is False)/* Recall that the Theorem of Lagrange states that the order of a subgroup of a finite group G must divide the order of G. ex: although the group A_4 has 12 elements and 6 divides 12, A_4 has no subgroup of order 6.
   2. *Advanced group theory:*
      - 
   3. *Rings and Fields*
      - *Definition:* A ring in which the multiplication is commutative is a commutative ring. A ring with a multiplicative identity element is a ring with unity; the multiplicative identity element 1 is called “unity.”
      - *Definition:* Let R be a ring with unity 1 \neq 0. An element u in R is a *unit* of R if it has a multiplicative inverse in R. If every nonzero element of R is a unit, then R is a *division ring* (or *skew field*). A field is a commutative division ring. A noncommutative division ring is called a *“strictly skew field.”* \\
	ex: Q, R, C, and Z_p for p a prime number are all fields.
      - *Definition:* If a and b are two nonzero elements of a ring R such that ab = 0, then a and b are *divisors of 0* (or *0 divisors*).
      - *Remark:* If R is a ring with unity and a is a unit in R, then a is not a divisor of 0. To see this, note that if $ab = 0$, then $a^{−1}ab = 0$, so $b = 0$. Similarly, if $ba = 0$, then $baa^{−1} = 0$, so $b = 0$. The theorem below shows that in the ring Z_n every element is either 0, a unit, or a 0 divisor.
      - *Theorem:* Let m \in Z_n. Either m = 0, m is relatively prime to n, in which case m is a unit in Z_n, or m is not relatively prime to n, in which case m is a 0 divisor in Zn.
      - *Theorem:* /The cancellation laws hold in a ring R if and only if R has no divisors of 0./
      - *Definition:* An integral domain D is a commutative ring with unity 1 \neq 0 that contains no divisors of 0. \\
	/Thus, if the coefficients of a polynomial are from an integral domain, one can solve a polynomial equation in which the polynomial can be factored into linear factors in the usual fashion by setting each factor equal to 0./
      - *Definition /(the characteristic of a ring):* If for a ring R a positive integer n exists such that n.a = 0 for all a \in R, then *the least such positive integer* is the characteristic of the ring R. If no such positive integer exists, then R is of *characteristic 0*. \\
	ex: The ring Zn is of characteristic n, while Z, Q, R, and C all have characteristic 0.
      - *Theorem:* The set R[x] of all polynomials in an indeterminate x with coefficients in a ring R is a ring under polynomial addition and multiplication. If R is commutative, then so is R[x], and if R has unity 1 \neq 0, then 1 is also unity for R[x]
   4. *The Evaluation Homomorphisms*
      - *Theorem /(The Evaluation Homomorphisms for Field Theory)/:*
	+ Let F be a subfield of a field E, let $\alpha$ be any element of E, and let x be an indeterminate. The map $\phi_\alpha : F[x] \to E$ defined by
	  \[ \phi_\alpha (a_0 + a_1x + ...  + a_nx^n) = a_0 + a_1\alpha + ... + a_n\alpha^n \]
	  for $(a_0 + a_1x + ...  + a_nx^n) \in F[x]$ is a homomorphism of F[x] into E. Also, $\phi_\alpha(x) = \alpha$, and $\phi_\alpha$ maps F isomorphically by the identity map; that is, $\phi_\alpha(a) = a$ for $a \in F$. The homomorphism $\phi_\alpha$ is *evaluation at* $\alpha$.
      - *Definition /(Irreducible Polynomials)/:*
	+ A nonconstant polynomial f(x) \in F[x] is *irreducible over* F or is an *irreducible polynomial in* F[x] if f(x) cannot be expressed as a product g(x)h(x) of two polynomials g(x) and h(x) in F[x] both of lower degree than the degree of f(x). If f(x) \in F[x] is a nonconstant polynomial that is not irreducible over F, then f (x) is reducible over F.
	+ It is worthwhile to remember that the units in F[x] are precisely the nonzero elements of F. Thus we could have defined an irreducible polynomial f(x) as a nonconstant polynomial such that in any factorization f(x) = g(x)h(x) in F[x], either g(x) or h(x) is a unit.
   5. *Prime and maximal ideals*
      - *Theorem* Let R be a commutative ring with unity. Then M is a maximal ideal of R if and only if R/M is a field
      - *Corollary* A commutative ring with unity is a field if and only if it has no proper nontrivial ideals.
      - *Definition /(prime ideal)/:* An ideal N \neq R in a commutative ring R is a prime ideal if ab \in N implies that either a \in N or b \in N for a, b \in R.
      - *Remark:*
	+ The definition of a prime ideal may seem a little strange. It is, however, a natural generalization of the notion of a “prime” in the integers Z. Let n be a nonnegative integer. According to the above definition the ideal nZ is a prime ideal provided n \ne 1 (to ensure that the ideal is proper) and provided every time the product ab of two integers is an element of nZ, at least one of a, b is an element of nZ. Put another way, if n \neq 0, it must have the property that whenever n divides ab, n must divide a or divide b. This is equivalent to the usual definition that n is a prime number. Thus the /prime ideals of Z are just the ideals pZ of Z generated by prime numbers p together with the ideal 0./
      - *Theorem* Let R be a commutative ring with unity, and let N \neq R be an ideal in R. Then R/N is an integral domain if and only if N is a prime ideal in R.
      - *Corollary* Every maximal ideal in a commutative ring R with unity is a prime ideal.
      - *Theorem* Let R be a ring with unity. If R has characteristic n > 1, then R contains a subring isomorphic to Z_n. If R has characteristic 0, then R contains a subring isomorphic to Z.
      - *Theorem*
	+ A field F is either of prime characteristic p and contains a subfield isomorphic to Z_p or of characteristic 0 and contains a subfield isomorphic to Q.
	+ Thus every field contains either a subfield isomorphic to Z_p for some prime p or a subfield isomorphic to Q. These fields Z_p and Q are the fundamental building blocks on which all fields rest.
      - *Definition* The fields Z_p and Q are *prime fields.*
   6. *Ideal Structure in F[x]*
      - *Theorem* If F is a field, every ideal in F[x] is principal.
      - *Theorem* An ideal <p(x)> \neq {0} of F[x] is maximal if and only if p(x) is irreducible over F.
   7. *Application to Unique Factorization in F[x]*
   8. *Modules over a Ring*
      - *Definition:*
	+ Let R be a ring with unity. A left R-module is an abelian group M under addition together with an operation of scalar multiplication of each element of M by each element of R on the left, such that for all a, b \in R and α, β \in M the following conditions are satisfied: \\
	  M1 : aα \in M \\
	  M2 : a(bα) = (ab)α \\
	  M3 : (a + b)α = (aα) + (bα) \\
	  M4 : a(α + β) = (aα) + (aβ) \\
	  M5 : 1α = α.
	+ Ex: Elements of R^n (written as column vectors) can be multiplied on the left by elements in the ring Mn(R) of n × n matrices with real number entries. The five properties defining an R-module are all satisfied, which implies R^n is an Mn(R)-module.
	+ In general an R-module need not have a basis, and even if it does, in some cases two bases may have a different number of elements.
   9. *Unique factorization domains*
      - 
* Pandas
  1. Groupby
     - Return groupby object
     - When chain with statical methods, return series or dataframe with group index.
       So we can use vectorize operation like: (df.groupby[ ['A','B'] ].size()/df.groupby['A'].size()).reset_index(name="tỷ lệ"): tính tỷ lệ % các thành phần của B trong từng group A
     - Khác biệt giữa size() và count(): size tính tất cả các dòng của group kể cả na -> do đó trả về group index và 1 cột mới chứa tổng số dòng trong mỗi group (series nếu as_index=false, dataframe nếu as_index=true - vì chuyển group index sang cột - tương đương với reset_index) , count chỉ đếm các dòng non-na ở từng cột sau group -> do đó trả về group index và tổng số dòng non-na cho mỗi cột sau group (datframe nếu có nhiều cột, series nếu chỉ có 1 cột).
  2. Vectorize operation
     - Khi pandas thực hiện phép tính dựa trên 2 data frame, vd: df3 = df1.A + df2.C, thì pandas sẽ tính toán các hàng dựa trên index (không cần trùng tên index nếu chỉ có duy nhất 1 index, phải trùng tên index nếu có nhiều lớp index), *KHông nhất thiết 2 dataframe phải cùng số hàng, kết quả trả về sẽ bằng tổng số index trùng và index không trùng giữa 2 dataframe*, những index nào không trùng giữa 2 dataframe thì sẽ trả về nan 
* Math road map
** 13/07/2023:
   1. You've done introduction of Analysis I, II, and functional analysis. That means you've just touch on very surface of it, i.e just some important definitions and its properties.
   2. Now, you should do the same thing with algebra
   3. Then, learn deeply (that mean you must take time to do a lot of excercises) probability, statistisc, and machine learning.
   4. Because learning deeply on those objects might take a lot of time to gain enough knownledge to do useful things (about 2 - 3 years), you must learn pratical things to earn money like web apps, mobile apps, and window apps.
   5. Now web apps should be prioritized.
   6. You should do some research about some trend:
      + Progressive web apps (PWA): these apps work like moblie apps, fast loading, offline working, and push nortification. ex: uber, twitter.
      + Accelerated mobile pages (AMP): faster load on mobile devices. ex: news apps
      + single page applications (SPA): only one page, without reloading when users interact. ex: Gmail, google maps, facebook.
      + you shoul youn Dajango at first because you are learning it, then might consider MERN stack. 
* Note
  - You seem to be insecure about your understanding of higher-level topics, so you continuously and obsessively revisit lower-level topics, despite that this is probably not necessary: really, if you got into a program for an M.Sc in Mathematics, you probably don't need to re-read books on naive set theory.
  - You seem to be obsessively pedantic about details. This is the way most beginning mathematicians start out --- making sure that all their proofs are definitely watertight --- and as they progress, they allow themselves a little more leeway in the rigor of their proofs: certain statements just become obvious and don't feel worth the time to prove. Now, you are clearly not a beginning student, so this is a fairly atypical behavior.
  - The two points above, in combination, more or less waste a great deal of time for you, and paralyze your learning.
  - This actually reads like a textbook case of a particular type of procrastination to me. In particular, your pedantic attention to detail (even regarding comparatively unimportant aspects, like the layout and formatting of your notes) is commensurate with perfectionist behavior. Indeed, to me this reads like *perfectionist procrastinator-type behavior*: you try to *perfect every aspect of the less important tasks* (taking notes, revisiting the most elementary set theory, etc.) and then don't have the time or energy for the more important tasks, like studying complex analysis.
  - This is a *very subtle and dangerous form of procrastination*, because you *mentally trick yourself into thinking that you're doing important work* (re-reading DeMorgan's Laws, making your notes pretty) when you're really not. *You're doing things you already know how to do (like proving elementary results or typing up some LATEX ), which is a 'safe', comfortable activity, whereas the work that you actually should be doing is more of a challenge, which you are avoiding with this form of procrastination.*
  - This form of procrastination is sometimes accompanied by some intellectual insecurity or anxiety.
  - I do not hold any formal qualifications in the field of psychology, so you should take my judgement with a grain of salt. However, I suggest the following two coping strategies:
    + When you find yourself doing something that seems somewhat unnecessary, like looking back at elementary set theory: ask yourself if what you're currently doing is really necessary for your learning. If the answer is not a clear-cut "yes", then stop and get back to your initial task. Use self-control.
    + See a psychologist or counselor about this problem. Issues like this are fairly commonplace, so you'll be in good hands. Good Luck!
